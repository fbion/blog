<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>k8s on Shining Moon</title>
    <link>https://blog.monsterxx03.com/tags/k8s/</link>
    <description>Recent content in k8s on Shining Moon</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>monsterxx03</copyright>
    <lastBuildDate>Mon, 29 Apr 2019 15:56:12 +0800</lastBuildDate>
    
	<atom:link href="https://blog.monsterxx03.com/tags/k8s/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Jenkins on K8S</title>
      <link>https://blog.monsterxx03.com/2019/04/29/jenkins-on-k8s/</link>
      <pubDate>Mon, 29 Apr 2019 15:56:12 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2019/04/29/jenkins-on-k8s/</guid>
      <description>最近在把 jenkins 迁移到 k8s, 具体怎么 setup 的不赘述了(helm chart, jenkins home 目录挂pvc, jenkins kubernetes-plugin).
jenkins 跑 k8s 好处是可以方便得做分布式 build, 每次 trigger 一个 job 的时候自动起一个 pod 作为 jenkins slave agent, 结束了自动删掉. 在 aws 上结合 cluster-autoscaler 可以极大得扩展 ci 的并行能力, 降低成本.
记录一点过程中的坑.
装上 kubernetes-plugin 后,要想让 jenkins 的 job 在 pod 中跑, 必须用 pipeline 的方式编写 job 定义. script 和 declarative 两种方式都支持启动 pod. 如果用 shell 的方式编写, 不会跑在 pod 里，会直接在　master 的　workspace 里 build.
declarative 方式的例子:</description>
    </item>
    
    <item>
      <title>K8s Volume Resize on EKS</title>
      <link>https://blog.monsterxx03.com/2019/04/12/k8s-volume-resize-on-eks/</link>
      <pubDate>Fri, 12 Apr 2019 13:23:54 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2019/04/12/k8s-volume-resize-on-eks/</guid>
      <description>从 k8s 1.8 开始支持 PersistentVolumeClaimResize. 但 api 是 alpha 状态, 默认不开启, eks launch 的时候版本是 1.10, 因为没法改 control plane, 所以没法直接在 k8s 内做 ebs 扩容. 后来升级到了 1.11, 这个 feature 默认被打开了, 尝试了下直接在 EKS 内做 ebs 的扩容.
注意:
 这个 feature 只能对通过 pvc 管理的 volume 做扩容, 如果直接挂的是 pv, 只能自己按传统的 ebs 扩容流程在 eks 之外做. 用来创建 pvc 的 storageclass 上必须设置 allowVolumeExpansion 为 true  在 eks 上使用 pv/pvc,　对于需要 retain 的 volume, 我一般的流程是:
 在 eks 之外手工创建 ebs volume.</description>
    </item>
    
    <item>
      <title>Kubernetes 中的 pod 调度</title>
      <link>https://blog.monsterxx03.com/2018/12/16/kubernetes-%E4%B8%AD%E7%9A%84-pod-%E8%B0%83%E5%BA%A6/</link>
      <pubDate>Sun, 16 Dec 2018 13:09:20 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/12/16/kubernetes-%E4%B8%AD%E7%9A%84-pod-%E8%B0%83%E5%BA%A6/</guid>
      <description>定义 pod 的时候通过添加 node selector 可以让 pod 调度到有特定 label 的 node 上去, 这是最简单的调度方式. 其他还有更复杂的调度方式: node-taints/tolerations, node-affinity, pod-affinity, 来达到让某些类型的 pod 调度到一起, 让某些类型的 pod 不跑一起的效果.
Taints and Tolerations 如果 node 有 taints, 那只有能 tolerate 这些 taints 的 pod 才能调度到上面.
taint 的基本格式是: &amp;lt;key&amp;gt;&amp;lt;operator&amp;gt;&amp;lt;value&amp;gt;:&amp;lt;effect&amp;gt;
kubectl describe node xxx 可以看到节点的 taints, 比如 master 节点上会有:
Taints: node-role.kubernetes.io/master:NoSchedule  这里 key 是 node-role.kubernetes.io/master, 没有等号和 value, operator 就是 Exists , effect 是 NoSchedule.
master 节点上的这条 taint 就定义了只有能 tolerate 它的 pod 能调度到上面, 一般都是些系统 pod.</description>
    </item>
    
    <item>
      <title>EkS 评测 part-3</title>
      <link>https://blog.monsterxx03.com/2018/09/26/eks-%E8%AF%84%E6%B5%8B-part-3/</link>
      <pubDate>Wed, 26 Sep 2018 10:16:42 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/26/eks-%E8%AF%84%E6%B5%8B-part-3/</guid>
      <description>这篇记录对 ingress 的测试.
ingress 用来将外部流量导入　k8s 内的　service. 将 service 的类型设置为 LoadBalancer / NodePort 也可以将单个 service 暴露到公网, 但用 ingress 可以只使用一个公网入口,根据　host name 或　url path 来将请求分发到不同的 service.
一般　k8s 内的资源都会由一个 controller 来负责它的状态管理, 都由 kube-controller-manager 负责，　但 ingress controller 不是它的一部分，需要是视情况自己选择合适的 ingress controller.
在 eks 上我主要需要 ingress-nginx 和 aws-alb-ingress-controller. 注意, nginx inc 还维护一个 kubernetes-ingress, 和官方那个不是一个东西， 没测试过.
这里主要只测试了 ingress-nginx, 看了下内部实现, 数据的转发真扭曲&amp;hellip;.
ingress-nginx 用 helm 安装很简单: helm install nginx-ingress --namespace ingress
看看安装后多了些什么:
service: ingress service/mean-quetzal-nginx-ingress-controller LoadBalancer 172.</description>
    </item>
    
    <item>
      <title>eks 评测 part-2</title>
      <link>https://blog.monsterxx03.com/2018/09/21/eks-%E8%AF%84%E6%B5%8B-part-2/</link>
      <pubDate>Fri, 21 Sep 2018 10:28:17 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/21/eks-%E8%AF%84%E6%B5%8B-part-2/</guid>
      <description>上文测试了一下 EKS 和 cluster autoscaler, 本文记录对 persisten volume 的测试.
PersistentVolume 创建 gp2 类型的 storageclass, 并用 annotations 设置为默认 sc, dynamic volume provision 会用到:
kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: gp2 annotations: storageclass.kubernetes.io/is-default-class: &amp;quot;true&amp;quot; provisioner: kubernetes.io/aws-ebs reclaimPolicy: Retain parameters: type: gp2 fsType: ext4 encrypted: &amp;quot;true&amp;quot;  因为 eks 是基于 1.10.3 的, volume expansion 还是 alpha 状态, 没法自动开启(没法改 api server 配置), 所以 storageclass 的 allowVolumeExpansion, 设置了也没用. 这里 encrypted 的值必须是字符串, 否则会创建失败, 而且报错莫名其妙.
创建 pod 的时候指定一个已存在的 ebs volume apiVersion: v1 kind: Pod metadata: name: test spec: volumes: - name: test awsElasticBlockStore: fsType: ext4 volumeID: vol-03670d6294ccf29fd containers: - image: nginx name: nginx volumeMounts: - name: test mountPath: /mnt  kubectl -it test -- /bin/bash 进去看一下:</description>
    </item>
    
    <item>
      <title>EKS 评测</title>
      <link>https://blog.monsterxx03.com/2018/09/11/eks-%E8%AF%84%E6%B5%8B/</link>
      <pubDate>Tue, 11 Sep 2018 15:02:22 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/11/eks-%E8%AF%84%E6%B5%8B/</guid>
      <description>EKS 正式 launch 还没有正经用过, 最近总算试了一把, 记录一点.
Setup AWS 官方的 Guide 只提供了一个 cloudformation template 来设置 worker node, 我喜欢用 terraform, 可以跟着这个文档尝试:https://www.terraform.io/docs/providers/aws/guides/eks-getting-started.html 来设置完整的 eks cluster 和管理 worker node 的 autoscaling group.
设置完 EKS 后需要添加一条 ConfigMap:
apiVersion: v1 kind: ConfigMap metadata: name: aws-auth namespace: kube-system data: mapRoles: | - rolearn: arn:aws:iam::&amp;lt;account-id&amp;gt;:role/eksNodeRole username: system:node:{{EC2PrivateDNSName}} groups: - system:bootstrappers - system:nodes  这样 worker node 节点才能加入集群.
网络 之前一直没有在 AWS 上尝试构建 k8s 的一个原因, 就是不喜欢 overlay 网络, 给系统带来了额外的复杂度和管理开销, VPC flowlog 看不到 pod 之间流量, 封包后 tcpdump 不好 debug 应用层流量.</description>
    </item>
    
    <item>
      <title>Kubernetes in Action Notes</title>
      <link>https://blog.monsterxx03.com/2018/09/03/kubernetes-in-action-notes/</link>
      <pubDate>Mon, 03 Sep 2018 18:20:46 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/03/kubernetes-in-action-notes/</guid>
      <description>Miscellaneous notes when reading &amp;lt;Kubernetes in Action&amp;gt;.
api group and api version core api group need&amp;rsquo;t specified in apiVersion field.
For example, ReplicationController is on core api group, so only:
apiVersion: v1 kind: ReplicationController ...  ReplicationSet is added later in app group, v1beta2 version (k8s v1.8):
apiVersion: apps/v1beta2 1 kind: ReplicaSet  https://kubernetes.io/docs/concepts/overview/kubernetes-api/
ReplicationController VS ReplicationSet ReplicationController is replaced by ReplicationSet, which has more expressive pod selectors.
ReplicationController&amp;rsquo;s label selector only allows matching pods that include a certain label, ReplicationSet can meet multi labels at same time.</description>
    </item>
    
    <item>
      <title>AWS 的 K8S CNI Plugin</title>
      <link>https://blog.monsterxx03.com/2018/04/09/aws-%E7%9A%84-k8s-cni-plugin/</link>
      <pubDate>Mon, 09 Apr 2018 15:28:38 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/04/09/aws-%E7%9A%84-k8s-cni-plugin/</guid>
      <description>EKS 还没有 launch, 但 AWS 先开源了自己的 CNI 插件, 简单看了下, 说说它的实现和其他 K8S 网络方案的差别.
K8S 集群对网络有几个基本要求:
 container 之间网络必须可达，且不通过 NAT 所有 node 必须可以和所有 container 通信, 且不通过 NAT container 自己看到的 IP, 必须和其他 container 看到的它的 ip 相同.  Flannel in VPC flannel 是 K8S 的一个 CNI 插件, 在 VPC 里使用 flannel 的话, 有几个选择:
 通过 VXLAN/UDP 进行封包, 封包影响网络性能, 而且不好 debug 用 aws vpc backend, 这种方式会把每台主机的 docker 网段添加进 vpc routing table, 但默认 routing table 里只能有50条规则, 所以只能 50 个 node, 可以发 ticket 提升, 但数量太多会影响 vpc 性能.</description>
    </item>
    
  </channel>
</rss>