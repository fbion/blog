<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Shining Moon</title>
    <link>https://blog.monsterxx03.com/posts/</link>
    <description>Recent content in Posts on Shining Moon</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>monsterxx03</copyright>
    <lastBuildDate>Wed, 10 Apr 2019 22:33:49 +0800</lastBuildDate>
    
	<atom:link href="https://blog.monsterxx03.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SNET Dev Note</title>
      <link>https://blog.monsterxx03.com/2019/04/10/snet-dev-note/</link>
      <pubDate>Wed, 10 Apr 2019 22:33:49 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2019/04/10/snet-dev-note/</guid>
      <description>完成 SNET 初版后又做了些后续更新,　记录一点.
支持 http tunnel 配置文件里增加一个 proxy-type 选项, 默认为 ss, 可改成 http, 这样可以将 支持 http tunnel 的代理服务器作为 upstream(例如 squid). 填上 http-proxy- 开头 的选项就行.
实现上 client 端要对接 http tunnel 非常简单:
 client 发送请求: Connect tgt-host:tgt-port HTTP/1.1 server response: HTTP/1.1 200, 即表示 server 端支持 http tunnel client 后续向该 tcp connection 写入的数据都会被 server 转发到 tgt-host:tgt-port  改动的时候把 upstream proxy 的部分重构了一下, 抽了个 Proxy interface 出来, 后续想对接其他协议方便扩展.
对 udp 支持的尝试 对 tcp 流量的转发能通过 iptables REDIRECT 实现的, 通过 getsockoption 可以知道 tcp connection 的原目标, 但这对 udp 行不通, REDIRECT 之后拿不到原 target.</description>
    </item>
    
    <item>
      <title>SNET: Transparent SS proxy on Linux</title>
      <link>https://blog.monsterxx03.com/2019/03/31/snet-transparent-ss-proxy-on-linux/</link>
      <pubDate>Sun, 31 Mar 2019 22:19:46 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2019/03/31/snet-transparent-ss-proxy-on-linux/</guid>
      <description>日常使用 Linux 工作, Linux 下实现全局透明代理可以用 iptables + ss-redir, 要有比较好的上网体验还需要 ChinaDNS 配合 dnsmasq, 这一整套在路由器上搞一遍就算了, 在本地太麻烦了. 仔细想想这几个加起来的功能实现起来也并不复杂, 前阵子就写了个小东西, 用一个进程完成全局透明代理 + ChinaDNS + 国内外分流: https://github.com/monsterxx03/snet
目前的限制:
 不支持 ipv6 只支持 tcp (因为我的测试服务器不支持 udp, 以后再加上吧) 上游 server 只支持 ss  目的是一个进程 + 一个配置文件完成所有事情. 需要的 iptable 规则也全部内置了(包括 CN ip 段), 缺少灵活但对我够用了, 以后有需要再加上选项不自动配吧.
需要手工装下 ipset.
配置文件示例:
{ &amp;quot;listen-host&amp;quot;: &amp;quot;127.0.0.1&amp;quot;, &amp;quot;listen-port&amp;quot;: 1111, &amp;quot;ss-host&amp;quot;: &amp;quot;ss.example.com&amp;quot;, &amp;quot;ss-port&amp;quot;: 8080, &amp;quot;ss-chpier-method&amp;quot;: &amp;quot;aes-256-cfb&amp;quot;, &amp;quot;ss-passwd&amp;quot;: &amp;quot;passwd&amp;quot;, &amp;quot;cn-dns&amp;quot;: &amp;quot;114.114.114.114&amp;quot;, &amp;quot;fq-dns&amp;quot;: &amp;quot;8.8.8.8&amp;quot;, &amp;quot;enable-dns-cache&amp;quot;: true, &amp;quot;mode&amp;quot;: &amp;quot;local&amp;quot; }  ss 协议实现用的是 shadowsocks-go, 所以 cipher 就是 go 版支持的那些: https://github.</description>
    </item>
    
    <item>
      <title>Celery Time Limit 的坑</title>
      <link>https://blog.monsterxx03.com/2019/03/28/celery-time-limit-%E7%9A%84%E5%9D%91/</link>
      <pubDate>Thu, 28 Mar 2019 17:37:29 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2019/03/28/celery-time-limit-%E7%9A%84%E5%9D%91/</guid>
      <description>之前用 celery 做的 task 都是一些很简单轻量级的 task, 从来没触发过 timeout, 最近加入了一些复杂很耗时的 task, 碰到一些 time limit 的坑.
celery 中 time limit 有两种, soft_time_limit 和 hard_time_limit, 区别是 soft_time_limit 会在内部抛一个 Exception, task 可以 catch 自行处理. hard time limit 没法被 catch.
使用如下:
from myapp import app from celery.exceptions import SoftTimeLimitExceeded @app.task def mytask(): try: do_work() except SoftTimeLimitExceeded: clean_up_in_a_hurry() 我 celery pool 用的是 gevent, 实际上在现在的实现里 gevent 做 worker pool 的时候会忽略 soft_time_limit, 只有 hard_time_limit 会被触发(通过 gevent.Timeout 实现).
坑爹的是文档里写的是错的: http://docs.</description>
    </item>
    
    <item>
      <title>管理负载</title>
      <link>https://blog.monsterxx03.com/2019/02/12/%E7%AE%A1%E7%90%86%E8%B4%9F%E8%BD%BD/</link>
      <pubDate>Tue, 12 Feb 2019 13:08:29 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2019/02/12/%E7%AE%A1%E7%90%86%E8%B4%9F%E8%BD%BD/</guid>
      <description>最近在看 google 的 &amp;lt;The Site Reliablity Workbook&amp;gt;, 其中有一章是&amp;rdquo;Manage load&amp;rdquo;, 内容还挺详细的, 结合在 aws 上的经验做点笔记.
Load Balancing 流量的入口是负载均衡, 最最简单的做法是在 DNS 上做 round robin, 但这样很依赖 client, 不同的 client 可能不完全遵守 DNS 的 TTL, 当地的 ISP 也会有缓存.
google 用 anycast 技术在自己的网络中通过 BGP 给一个域名发布多个 endpoint, 共享一个 vip(virtual ip), 通过 BGP routing 来将用户的数据包发送到最近的 frontend server, 以此来减少 latency.
但只依赖 BGP 会带来两个问题:
 某个地区的用户过多会给最近的 frontend server 带来过高的负载 ISP 的 BGP 路由会重计算, 当 BGP routing 变化后, 进行中的 tcp connection 会被 reset(同一个 connection 上的后续数据包被发送到不同的 server, tcp session 不存在于新 server 上)  为了解决原生 BGP anycast 的问题, google 开发了 Maglev, 即使路由发生了变化(routing flap), connection 也不断开, 把这种方式叫做 stablized anycast.</description>
    </item>
    
    <item>
      <title>从去年的一个patch说起</title>
      <link>https://blog.monsterxx03.com/2018/12/29/%E4%BB%8E%E5%8E%BB%E5%B9%B4%E7%9A%84%E4%B8%80%E4%B8%AApatch%E8%AF%B4%E8%B5%B7/</link>
      <pubDate>Sat, 29 Dec 2018 15:14:46 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/12/29/%E4%BB%8E%E5%8E%BB%E5%B9%B4%E7%9A%84%E4%B8%80%E4%B8%AApatch%E8%AF%B4%E8%B5%B7/</guid>
      <description>去年对线上业务做了一些性能优化, 当时把 http client 从 requests 换成了 geventhttpclient , 上线后发起 rpc 调用的 server 整体负载低了很多, 但 client 端 latency 却高了很多, 经过 debug 觉得问题是 geventhttpclient 把 header 和 body 通过两次 sock send 发出的额外开销造成的, 尝试 修改成一次 send 后 latency 就恢复了: https://github.com/gwik/geventhttpclient/pull/85
最近在调试 gunicorn 的代码时候, 看到它建立 socket 的时候设置了 TCP_NODELAY, 在很多项目里看到过这个 tcp option, 但没细究过, man tcp 得知是用来关闭 tcp 里的 nagle 算法的. nagle 在 linux 的 默认 tcp 协议栈里是开启的, 当发送的数据包 size 小于 mss 的时候会在内存里 buffer 起来, 积累起来后再发送, 目的是提高带宽利用率, 毕竟 payload 只发一次字节也要带上 40 字节的 ip+tcp header.</description>
    </item>
    
    <item>
      <title>Kubernetes 中的 pod 调度</title>
      <link>https://blog.monsterxx03.com/2018/12/16/kubernetes-%E4%B8%AD%E7%9A%84-pod-%E8%B0%83%E5%BA%A6/</link>
      <pubDate>Sun, 16 Dec 2018 13:09:20 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/12/16/kubernetes-%E4%B8%AD%E7%9A%84-pod-%E8%B0%83%E5%BA%A6/</guid>
      <description>定义 pod 的时候通过添加 node selector 可以让 pod 调度到有特定 label 的 node 上去, 这是最简单的调度方式. 其他还有更复杂的调度方式: node-taints/tolerations, node-affinity, pod-affinity, 来达到让某些类型的 pod 调度到一起, 让某些类型的 pod 不跑一起的效果.
Taints and Tolerations 如果 node 有 taints, 那只有能 tolerate 这些 taints 的 pod 才能调度到上面.
taint 的基本格式是: &amp;lt;key&amp;gt;&amp;lt;operator&amp;gt;&amp;lt;value&amp;gt;:&amp;lt;effect&amp;gt;
kubectl describe node xxx 可以看到节点的 taints, 比如 master 节点上会有:
Taints: node-role.kubernetes.io/master:NoSchedule  这里 key 是 node-role.kubernetes.io/master, 没有等号和 value, operator 就是 Exists , effect 是 NoSchedule.
master 节点上的这条 taint 就定义了只有能 tolerate 它的 pod 能调度到上面, 一般都是些系统 pod.</description>
    </item>
    
    <item>
      <title>Debug Skills on Linux</title>
      <link>https://blog.monsterxx03.com/2018/12/03/debug-skills-on-linux/</link>
      <pubDate>Mon, 03 Dec 2018 22:47:51 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/12/03/debug-skills-on-linux/</guid>
      <description>This post will show several commands used for debugging on linux server, all examples are tested on ubuntu 18.04, some tools are not installed by default, you can installl by sudo apt install xxx. Some commands must be used via sudo.
System resources can be classified in three main categories: compute, storage, and network. Usually, when you come to a performance issue, it&amp;rsquo;s always caused by exhaustion of those resources.</description>
    </item>
    
    <item>
      <title>杂谈</title>
      <link>https://blog.monsterxx03.com/2018/11/30/%E6%9D%82%E8%B0%88/</link>
      <pubDate>Fri, 30 Nov 2018 17:39:00 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/11/30/%E6%9D%82%E8%B0%88/</guid>
      <description>屋里有两个钟，一个快 5 分钟，　一个慢 5 分钟,　一直懒得把它们调正, 有种莫名的时间撕裂感, 好像还挺喜欢.还有一个月 2018 就过去了, 我想想最近都干嘛了.
最近看的书 读完了 &amp;lt;a philosophy of software design&amp;gt;, 书是好书, 就是好贵(花了我260&amp;hellip;). 本来想专门写一篇的,但开了个头发却发现没太多可写的. 书里提到的问题都碰到过, 解决方法和建议其实也一直在用, 没有什么银弹, 等再践行一段时间再说吧. PS: 收益最大的是讲注释的章节.
昨晚看完了 &amp;lt;夜行&amp;gt;. 森见登美彦的书, 改编的动画倒是看过不少, 书以前只看过 &amp;lt;有顶天家族&amp;gt;. 这本风格差得挺远,　通篇五里雾中的感觉, 有点　&amp;lt;1Q84&amp;gt;　的意思. &amp;ldquo;世界是一场夜&amp;rdquo;, 后半部分看到这句话的时候, 起了鸡皮疙瘩,　夜行和曙光世界里的岸田过着完全不同的生活, 契机只是鞍马火祭上的偶遇. 是不是真的存在一个和现实完全对立的世界, 跨越的分界线只是那一点点契机?那个世界的自己又过得到好还是差呢?　定的 &amp;lt;企鹅公路&amp;gt; 还在路上, 为什么有人已经收到了?
今敏的短篇漫画集 &amp;lt;梦的化石&amp;gt;, 只看了个开头几篇, 怎么说呢, 画的真烂啊&amp;hellip;故事莫名奇妙, 大师放弃漫画做动画是对的.
最近的工作 干了几件事:
 迁了一部分数据库到 aurora 上, 效果不错, 但挺贵哦. 用 Bloomfilter 改写了部分业务逻辑, 顺便了解了下其他的 probabilistic data structure, 挺有趣的, 只恨高数都还给老师了, 证明过程看得一头雾水, 要不补一下?</description>
    </item>
    
    <item>
      <title>用 Bloom filter 给推荐列表去重</title>
      <link>https://blog.monsterxx03.com/2018/11/17/%E7%94%A8-bloom-filter-%E7%BB%99%E6%8E%A8%E8%8D%90%E5%88%97%E8%A1%A8%E5%8E%BB%E9%87%8D/</link>
      <pubDate>Sat, 17 Nov 2018 13:58:27 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/11/17/%E7%94%A8-bloom-filter-%E7%BB%99%E6%8E%A8%E8%8D%90%E5%88%97%E8%A1%A8%E5%8E%BB%E9%87%8D/</guid>
      <description>之前产品里有一个功能是每天给用户推荐一批文章,要保证最后推给用户的文章每天不重复. 原先的实现很直接, 每次推送时候记录下用户 id 和 topic id 的键值对, 拿到新 topic 列表后,取出曾经给该用户推送过的文章列表, 两个 set 去重.
这个实现的问题很明显, 存储空间量太大(M * N), user id (int64) + topic id (int64) = 16 bytes, 1 million 的用户, 每天给用户推送10篇文章, 一年要存储: 16 * 10 * 365 * 1M = 54.4GB. 查询效率也很低,要么一次取所有已读 topic id, 要么把要推送的 topic id 都丢进数据库去重.
Bloom filter 比较合适解决大集合去重的问题, 给定一个 key, bloom filter 返回不存在,则该 key 在集合中一定不存在, bloom filter 返回存在, 该元素仍旧可能存在集合中.
可以看出当元素存在时, bloom filter 是有一定误判率的, 所以说 bloom filter 是一种 probabilistic 数据结构, 存在 false positive 的情况, 但当元素不存在时结果正确, 很适合上面那个去重的例子, 只要 error rate 足够低, 就会有小概率漏推, 但不会重推.</description>
    </item>
    
    <item>
      <title>濑户内海的风与阳</title>
      <link>https://blog.monsterxx03.com/2018/11/04/%E6%BF%91%E6%88%B7%E5%86%85%E6%B5%B7%E7%9A%84%E9%A3%8E%E4%B8%8E%E9%98%B3/</link>
      <pubDate>Sun, 04 Nov 2018 23:31:07 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/11/04/%E6%BF%91%E6%88%B7%E5%86%85%E6%B5%B7%E7%9A%84%E9%A3%8E%E4%B8%8E%E9%98%B3/</guid>
      <description>上月休假去濑户内海溜达了一圈, 一个比想象中美太多的地方.
对濑户内海的印象, 要追溯到高中时看的一部搞笑番 &amp;lt;濑户花嫁&amp;gt;, 挺有意思的片子, 爆笑之余, 对濑户内海这个地方有了模模糊糊的印象.
去年去了青森和九州, 就想着再去个日本犄角旮旯的地吧, 四国就被提上了日程, 稍做攻略, 发现濑户内海就这里, 兴趣来了.
明年三月的时候濑户内海有艺术祭, 那会估计就被世界各地的人给挤爆了, 不凑这热闹, 还是10月去吧.
大致行程: 上海 -&amp;gt; 高松 -&amp;gt; 小豆岛 -&amp;gt; 丰岛 -&amp;gt; 直岛. 除了在小豆岛上呆了一晚上，其他时候都住在了高松.
微笑的高松车站:
小豆岛是个挺无趣的地方, 类似度假村, 当地酒店设施比较齐全, 还有个电影的拍摄基地. 岛上交通比较麻烦, 班次好少,本来想去寒霞溪看看, 结果在车站等了半钟头才发现去那边的巴士要20号才开始运作, 不得已坐车回码头. 嘛, 中间经历了一段好难描述的迷路之旅&amp;hellip;.但是吃到了此行最棒的乌冬面!
小豆岛的夜晚真的很黑, 很黑, 云好厚, 没有星光, 隔了好远才有一个路灯, 岛上环境太好, 导致有很多蜘蛛网，迎面撞上了好几个. 晚上去超市买了支洗面奶, 柑橘味的, 好闻得忍不住舔了一口, 是苦的! 哦，对了, 橄榄园的橄榄味冰淇淋很推荐.
丰岛上去了两个地方, 心脏音博物馆和丰岛美术馆.
心脏音博物馆建在偏僻的海滩边, 外面有个看起来很孤独的姑娘在本子上写着什么. 馆乍一看以为是个废屋:
进去只有一间黑屋子, 中间有个白织灯, 音响会播放以前游客录下的心跳声, 白织灯随着心跳声忽闪忽灭, 在黑屋子里一个人坐了会, 明明音响声很大, 心情却不可思议得平静. 好像在和一群人的灵魂对话.
丰岛美术馆, 是这一行最喜欢的地方, 路上被一个大姐带叉了路, 拎着箱子走了条山路上去, 走到山顶发现另一遍是靠海的大马路, 风景好路也好走, 简直了&amp;hellip;.</description>
    </item>
    
    <item>
      <title>AWS Aurora DB</title>
      <link>https://blog.monsterxx03.com/2018/10/31/aws-aurora-db/</link>
      <pubDate>Wed, 31 Oct 2018 15:23:45 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/10/31/aws-aurora-db/</guid>
      <description>最近在把部分用 RDS 的 MySQL 迁移到 aurora 上去, 读了下 aurora 的 paper, 顺便和 RDS 的架构做些对比.
Paper notes  存储计算分离 redo log 下推到存储层 副本: 6 副本 3 AZ(2 per az), 失去一个 AZ + 1 additoinal node 不会丢数据(可读不可写). 失去一个 AZ (或任意2 node) 不影响数据写入. 10GB 一个 segment, 每个 segment 6 副本一个 PG (protection group), 一 AZ　两副本. 在 10Gbps 的网络上, 修复一个 10GB 的segment 需要 10s.  MySQL 一个应用层的写会在底层产生很多额外的写操作，会带来写放大问题:
redo log 用来 crash recovery, binlog 会上传 s3　用于 point in time restore.</description>
    </item>
    
    <item>
      <title>为 service 制定 SLO</title>
      <link>https://blog.monsterxx03.com/2018/10/15/%E4%B8%BA-service-%E5%88%B6%E5%AE%9A-slo/</link>
      <pubDate>Mon, 15 Oct 2018 11:31:05 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/10/15/%E4%B8%BA-service-%E5%88%B6%E5%AE%9A-slo/</guid>
      <description>通常我们使用云服务的时候, 服务提供商会提供 SLA(Service Level Aggrement),作为他们提供的服务质量的标准(常说的几个9),达不到会进行赔偿. 比如 AWS 的计算类服务: https://aws.amazon.com/compute/sla/ .
对公司自己 host 的 service, 我们内部也需要一些技术指标来 track 我们为客户提供的服务质量如何, 这个叫做 SLO(Service Level Objective). 也可以把他当成一个对内的,没有赔偿协议的SLA.
定义指标 我主要 track 两个指标:
 Availability (服务的可用性) Quality (服务质量)  Availability 的定义, 以前用简单的 service uptime 来定义, 在集群外部用一个 service check 定时 ping 我们 service　的 check endpoint, 失败就定义为 failure.
但这样的做法很粗糙, 和实际用户体验到的 service quality 相差比较大, 比如部署了新的代码，bug 导致某个很常用的 api　持续性抛 500. 此时我们的 service check　还是 up, 但用户就觉得你服务器挂了.
现在我用失败的 request 的个数来定义我们的 availability.</description>
    </item>
    
    <item>
      <title>在 redshift 中计算 p95 latency</title>
      <link>https://blog.monsterxx03.com/2018/10/12/%E5%9C%A8-redshift-%E4%B8%AD%E8%AE%A1%E7%AE%97-p95-latency/</link>
      <pubDate>Fri, 12 Oct 2018 14:49:13 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/10/12/%E5%9C%A8-redshift-%E4%B8%AD%E8%AE%A1%E7%AE%97-p95-latency/</guid>
      <description>p95 latency 的定义: 把一段时间的 latency 按照从小到大排序, 砍掉最高的 %5, 剩下最大的值就是 p95 latency. p99, p90 同理.
p95 latency 表示该时间段内 95% 的 reqeust 都比这个值快.
一般我直接看 CloudWatch, 和 datadog 算好的 p95 值. 这次看看怎么从 access log 里直接计算 p95 latency.
假设在 redshift 中有一张表存储了应用的 access log, 结构如下:
CREATE TABLE access_log ( url string, time string, resp_time real );     url time resp_time     /test1 2018-10-11T00:10:00.418480Z 0.123   /test2 2018-10-11T00:12:00.512340Z 0.321    要算 p95 很简单, 把 log 按分钟数分组, 用 percentile_cont 在组内按 resp_time 排序计算 就能得到:</description>
    </item>
    
    <item>
      <title>EkS 评测 part-3</title>
      <link>https://blog.monsterxx03.com/2018/09/26/eks-%E8%AF%84%E6%B5%8B-part-3/</link>
      <pubDate>Wed, 26 Sep 2018 10:16:42 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/26/eks-%E8%AF%84%E6%B5%8B-part-3/</guid>
      <description>这篇记录对 ingress 的测试.
ingress 用来将外部流量导入　k8s 内的　service. 将 service 的类型设置为 LoadBalancer / NodePort 也可以将单个 service 暴露到公网, 但用 ingress 可以只使用一个公网入口,根据　host name 或　url path 来将请求分发到不同的 service.
一般　k8s 内的资源都会由一个 controller 来负责它的状态管理, 都由 kube-controller-manager 负责，　但 ingress controller 不是它的一部分，需要是视情况自己选择合适的 ingress controller.
在 eks 上我主要需要 ingress-nginx 和 aws-alb-ingress-controller. 注意, nginx inc 还维护一个 kubernetes-ingress, 和官方那个不是一个东西， 没测试过.
这里主要只测试了 ingress-nginx, 看了下内部实现, 数据的转发真扭曲&amp;hellip;.
ingress-nginx 用 helm 安装很简单: helm install nginx-ingress --namespace ingress
看看安装后多了些什么:
service: ingress service/mean-quetzal-nginx-ingress-controller LoadBalancer 172.</description>
    </item>
    
    <item>
      <title>eks 评测 part-2</title>
      <link>https://blog.monsterxx03.com/2018/09/21/eks-%E8%AF%84%E6%B5%8B-part-2/</link>
      <pubDate>Fri, 21 Sep 2018 10:28:17 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/21/eks-%E8%AF%84%E6%B5%8B-part-2/</guid>
      <description>上文测试了一下 EKS 和 cluster autoscaler, 本文记录对 persisten volume 的测试.
PersistentVolume 创建 gp2 类型的 storageclass, 并用 annotations 设置为默认 sc, dynamic volume provision 会用到:
kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: gp2 annotations: storageclass.kubernetes.io/is-default-class: &amp;quot;true&amp;quot; provisioner: kubernetes.io/aws-ebs reclaimPolicy: Retain parameters: type: gp2 fsType: ext4 encrypted: &amp;quot;true&amp;quot;  因为 eks 是基于 1.10.3 的, volume expansion 还是 alpha 状态, 没法自动开启(没法改 api server 配置), 所以 storageclass 的 allowVolumeExpansion, 设置了也没用. 这里 encrypted 的值必须是字符串, 否则会创建失败, 而且报错莫名其妙.
创建 pod 的时候指定一个已存在的 ebs volume apiVersion: v1 kind: Pod metadata: name: test spec: volumes: - name: test awsElasticBlockStore: fsType: ext4 volumeID: vol-03670d6294ccf29fd containers: - image: nginx name: nginx volumeMounts: - name: test mountPath: /mnt  kubectl -it test -- /bin/bash 进去看一下:</description>
    </item>
    
    <item>
      <title>EKS 评测</title>
      <link>https://blog.monsterxx03.com/2018/09/11/eks-%E8%AF%84%E6%B5%8B/</link>
      <pubDate>Tue, 11 Sep 2018 15:02:22 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/11/eks-%E8%AF%84%E6%B5%8B/</guid>
      <description>EKS 正式 launch 还没有正经用过, 最近总算试了一把, 记录一点.
Setup AWS 官方的 Guide 只提供了一个 cloudformation template 来设置 worker node, 我喜欢用 terraform, 可以跟着这个文档尝试:https://www.terraform.io/docs/providers/aws/guides/eks-getting-started.html 来设置完整的 eks cluster 和管理 worker node 的 autoscaling group.
设置完 EKS 后需要添加一条 ConfigMap:
apiVersion: v1 kind: ConfigMap metadata: name: aws-auth namespace: kube-system data: mapRoles: | - rolearn: arn:aws:iam::&amp;lt;account-id&amp;gt;:role/eksNodeRole username: system:node:{{EC2PrivateDNSName}} groups: - system:bootstrappers - system:nodes  这样 worker node 节点才能加入集群.
网络 之前一直没有在 AWS 上尝试构建 k8s 的一个原因, 就是不喜欢 overlay 网络, 给系统带来了额外的复杂度和管理开销, VPC flowlog 看不到 pod 之间流量, 封包后 tcpdump 不好 debug 应用层流量.</description>
    </item>
    
    <item>
      <title>Kubernetes in Action Notes</title>
      <link>https://blog.monsterxx03.com/2018/09/03/kubernetes-in-action-notes/</link>
      <pubDate>Mon, 03 Sep 2018 18:20:46 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/03/kubernetes-in-action-notes/</guid>
      <description>Miscellaneous notes when reading &amp;lt;Kubernetes in Action&amp;gt;.
api group and api version core api group need&amp;rsquo;t specified in apiVersion field.
For example, ReplicationController is on core api group, so only:
apiVersion: v1 kind: ReplicationController ...  ReplicationSet is added later in app group, v1beta2 version (k8s v1.8):
apiVersion: apps/v1beta2 1 kind: ReplicaSet  https://kubernetes.io/docs/concepts/overview/kubernetes-api/
ReplicationController VS ReplicationSet ReplicationController is replaced by ReplicationSet, which has more expressive pod selectors.
ReplicationController&amp;rsquo;s label selector only allows matching pods that include a certain label, ReplicationSet can meet multi labels at same time.</description>
    </item>
    
    <item>
      <title>杂谈</title>
      <link>https://blog.monsterxx03.com/2018/09/01/%E6%9D%82%E8%B0%88/</link>
      <pubDate>Sat, 01 Sep 2018 12:03:42 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/09/01/%E6%9D%82%E8%B0%88/</guid>
      <description>忙了好一阵, 两个月没写了, 工作上的事告一段落, 也该补上这笔帐了, 老规矩, 随便写写 :)
最近在做什么? 把公司的代码环境从 python 2.7 升级到 python3.6, 前后忙了 3 个月, 50w 行代码, 也是够呛, 好歹算是顺利完成了, 具体的过程6月零散写过 几篇文章, 大差不差, 后续又碰了不少坑, 但也都能解决. 下一步打算基于 python3 的一些特性对代码做些重构, 从基础库开始吧.
最近看了什么书? &amp;lt;特别的猫&amp;gt;, 特别喜欢的一本书, 不是那种猫奴一昧赞美猫咪多么多么可爱的文字, 作者和猫咪过了一辈子, 把它们当成自己的朋友, 家人一样对待, 迫于无奈对猫做过残酷的事情, 也尽力照顾过病痛中的猫,把它从死亡边缘拉回来过, 猫给她带来的快乐和烦恼都在这本书里. 读着读着, 会产生一种错觉, 那一个个精灵古怪的小东西就自己脚边转悠. 作者是一个懂生活的人, 太羡慕了.
&amp;lt;Designing distributed systems&amp;gt; 列举了一些分布式系统的常见 pattern, 用 k8s 作为基础平台来讲解. 很小的一本书, 全力看的话,一个周末就能看完, 不能说很有帮助, 大部分内容基本都知道, 但作者文字很流畅, 顺着看下来权当理了一遍思路, 没接触过这类工作的人值得一看的.
&amp;lt;人类简史:从动物到上帝&amp;gt;断断续续看了 80% 多, 相当推荐的一本书, 作者从宏观角度把人类的进化历史娓娓道来, 很少看到读起来这么轻松的历史书, 不纠结于具体历史事件和人物, 用上帝之眼看人类历史. 作者很多观点很有趣, 人类从采集社会进化到农业社会, 从种族整体来看是成功的, 种群规模增加了, 但对个体来说未必, 采集社会时候的食物种类更丰富, 没有定居点,也没有财产概念,那会的原始人可能比封建社会的农民甚至现在的上班族更幸福(某种意义上).</description>
    </item>
    
    <item>
      <title>升级celery 到 4.2.0 碰到的坑</title>
      <link>https://blog.monsterxx03.com/2018/06/22/%E5%8D%87%E7%BA%A7celery-%E5%88%B0-4.2.0-%E7%A2%B0%E5%88%B0%E7%9A%84%E5%9D%91/</link>
      <pubDate>Fri, 22 Jun 2018 16:10:41 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/06/22/%E5%8D%87%E7%BA%A7celery-%E5%88%B0-4.2.0-%E7%A2%B0%E5%88%B0%E7%9A%84%E5%9D%91/</guid>
      <description>在把代码往 python3 迁移的过程中需要升级一些第三方库, 升级了 gevent 后发现 celery 有问题, 于是尝试把 celery 从3.1.25 升级到 4.2.0, 中间碰到了很多问题, 记录一点.
配置的变化 CELERY_ACCEPT_CONENT 之前默认是都允许的, 4.0 开始默认值只允许 json, 因为我用的是msgpack, 所以需要修改这个配置让它接受 msgpack.
CELERY_RESULT_SERIALIZER 之前默认是pickle, 现在默认也变成了json, 如果task 的返回结果是 binary 的话, json 无法处理,要么把结果 base64 编码, 要么把CELERY_RESULT_SERIALIZER 配置成 msgpack, pickle 明显 py2 / 3 不兼容, 没用.
CELERY_RESULT_BACKEND 使用 redis 的坑 配置了 CELERY_RESULT_BACKEND 后, 会把 task 执行结果存起来, 用redis 做backend 支持 expire, 默认 1 天.
我的 worker pool 是 gevent, 升级 4.2.0 上线之后, 报了很多奇怪的错, 全是把 task 插入 redis 时候报的错, 错误原因大致是因为redis client 的 socket 在不同的 greenlet 中被使用造成的, 所以有时候会尝试使用一个已经被关闭的 socket, 有时有 socket 还没有被建立, 而且全是在调用 redis subscribe channel 的时候出的错, channel list 还很长.</description>
    </item>
    
    <item>
      <title>编写 python 2/3 兼容代码</title>
      <link>https://blog.monsterxx03.com/2018/06/16/%E7%BC%96%E5%86%99-python-2/3-%E5%85%BC%E5%AE%B9%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Sat, 16 Jun 2018 14:38:26 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/06/16/%E7%BC%96%E5%86%99-python-2/3-%E5%85%BC%E5%AE%B9%E4%BB%A3%E7%A0%81/</guid>
      <description>上一篇 里简单得提了一点开始做 python 2 到 python3 迁移时候碰到的问题, 和工具的选择(推荐用 six).这篇讲下编写 python 2 / 3 兼容代码要注意的事情.
__future__ python2 里自带的向后兼容模块，将 python3 的一些语法行为 backport 到 python2 里, 使用的时候需要在文件头部声明, 作用域只在当前文件.
首先是几个在 python 2.7 里不用特意写，已经默认开启的特性:
 from __future__ import nested_scopes 2.2 开始就默认开启了，用于修改嵌套函数内的变量搜索作用域, 在此之前, 全局模块的优先级比被嵌套函数的父函数要高, 现在都没这个问题了. from __future__ import generators, yield 关键词, 2.3 默认支持. from __future__ import with_statement, with 关键词, 2.6 默认支持.  我显示开启的两个特性:
 from __future__ import print_function, 就是将 print 关键词变成函数啦, 导入后支持 python3 中 print 的完整参数，再用不带括号的 print 就会在文件被导入的时候报语法错误啦.</description>
    </item>
    
    <item>
      <title>杂谈松本清张</title>
      <link>https://blog.monsterxx03.com/2018/06/10/%E6%9D%82%E8%B0%88%E6%9D%BE%E6%9C%AC%E6%B8%85%E5%BC%A0/</link>
      <pubDate>Sun, 10 Jun 2018 17:15:29 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/06/10/%E6%9D%82%E8%B0%88%E6%9D%BE%E6%9C%AC%E6%B8%85%E5%BC%A0/</guid>
      <description>去年在 kindle 上买了套松本清张的合集, 总共有10本, 断断续续看到现在终于看完了第 9 本&amp;lt;隐花平原&amp;gt;, 随便扯一点(喂，为什么不看完最后一本!
松本清张 (1909 ~ 1992), 社会派推理开创人, 这套书里的作品各个年代都有, 最有名的&amp;lt;砂之器&amp;gt;(貌似仲间姐姐拍过剧?) 和 &amp;lt;点与线&amp;gt; 却没收录.
本格派讲究逻辑的精巧， 整个故事就像在玩密室逃脱一样, 一环扣一环, 最后谜底揭开的时候让人惊呼&amp;rdquo;卧槽&amp;rdquo;, 写的就很棒了, 但如果被提前剧透了, 就丧失了大半乐趣.
社会派就没那么多精巧的机关迷题了, 更多的把笔墨放在犯罪动机上, 案件本身和一些社会现象绑得比较近, 有印象看的第一本真正的社会派推理小说好像是东野圭吾的&amp;lt;恶意&amp;gt;, 开篇就把凶手告诉了你，全篇就是在讨论犯罪动机.
回到松本清张的书, 精巧机关的成分是0, 故事大多围绕着核心人物的社会身份展开, &amp;lt;死亡螺旋&amp;gt; 里是建筑业的官商勾结, &amp;lt;一个背叛日本的日本人&amp;gt; 里是外交官, &amp;lt;隐花平原&amp;gt; 是银行. 大多数故事没看多久读者都能猜到是怎么一回事, &amp;lt;十万分之一的偶然&amp;gt; 这本书只看了序我就猜到了真相(汗). 推理的过程也并不严禁, 关键线索经常是主角&amp;rdquo;无意中&amp;rdquo;, &amp;ldquo;碰巧&amp;rdquo;&amp;hellip;得到的, 甚至是随手看下报纸, 看到一则和案件风马牛不相及的案件, 却福尔摩斯附体, 费老大劲去查才把事件串了起来(&amp;lt;交错的场景&amp;gt;我说的就是你&amp;hellip;). 本格推理爱好者读起来, 估计处处是槽点.
又是什么东西吸引着我看了整整九本呢, 说来奇怪, 完全是和推理无关的东西, 是松本清张文字的触感, 说法不是很准确, 毕竟看的是译本. &amp;lt;富士山禁恋&amp;gt; (原名是&amp;lt;波之塔&amp;gt;, 谁改的鬼名字) 根本不算推理小说, 其实是个像昼颜那样的出轨故事, 一度看得我昏昏欲睡, 但对富士山树海的那段描写却特别有感觉, 一瞬间感觉自己被角色内心的那种虚无感给包围了, 有说法人站在高楼边上会产生跳下去的冲动, 读着那段景色描写, 好像也能理解望着树海的人想走进去的心理. &amp;lt;箱根杀人&amp;gt; 里清晨迷雾中的密谈场景也是如此.</description>
    </item>
    
    <item>
      <title>From python2 to python3</title>
      <link>https://blog.monsterxx03.com/2018/06/07/from-python2-to-python3/</link>
      <pubDate>Thu, 07 Jun 2018 16:41:57 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/06/07/from-python2-to-python3/</guid>
      <description>This article won&amp;rsquo;t provide perfect guide for porting py2 code to py3, just list the solutions I tried, the problems I come to, and my choices. I haven&amp;rsquo;t finished this project, also I haven&amp;rsquo;t gave up so far :).
Won&amp;rsquo;t explain too much about the differences between py2 and py3, will write down some corner cases which are easy to miss.
The codebase I&amp;rsquo;m working on:
 Only support python2.</description>
    </item>
    
    <item>
      <title>在python3.7 中实现python2.7 的内置 hash 函数</title>
      <link>https://blog.monsterxx03.com/2018/06/01/%E5%9C%A8python3.7-%E4%B8%AD%E5%AE%9E%E7%8E%B0python2.7-%E7%9A%84%E5%86%85%E7%BD%AE-hash-%E5%87%BD%E6%95%B0/</link>
      <pubDate>Fri, 01 Jun 2018 17:03:24 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/06/01/%E5%9C%A8python3.7-%E4%B8%AD%E5%AE%9E%E7%8E%B0python2.7-%E7%9A%84%E5%86%85%E7%BD%AE-hash-%E5%87%BD%E6%95%B0/</guid>
      <description>最近着手准备从 python2.7 迁移到 python3.7, 还没开始就碰到一个问题. 老系统里有一部分竟然是将 python 内置 hash 函数的结果存进了数据库, 这个做法绝对是错的, hash 的结果本来就没有保证过在各个版本的 python 中保证一致. 而且 python3 中算法完全变了, 默认在进程初始化的时候会用随机种子加进 hash 过程, 所以python 进程 一重启结果就不一样了. 木已成舟， 目前看将数据库里的值全部改掉是不可能了, 只能在 python3 中重新实现一下这个算法.
python2.7 中的hash 算法是 fnv (有修改), python3 中变成了 sip, pep-456.
fnv 的实现很简单， 引用 wikipedia 上的伪代码:
hash = FNV_offset_basis for each byte_of_data to be hashed hash = hash × FNV_prime hash = hash XOR byte_of_data return hash  FNV_prime 是 1000003, python 实现和标准 fnv 的不同在于, 在进入循环 hash 之前将数据左移了7位, 在最后又和长度做了次XOR, 生成的数据随机性更大一点.</description>
    </item>
    
    <item>
      <title>Use SNS &amp; SQS to build Pub/Sub System</title>
      <link>https://blog.monsterxx03.com/2018/05/23/use-sns-sqs-to-build-pub/sub-system/</link>
      <pubDate>Wed, 23 May 2018 18:05:28 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/05/23/use-sns-sqs-to-build-pub/sub-system/</guid>
      <description>Recently, we build pub/sub system based on AWS&amp;rsquo;s SNS &amp;amp; SQS service, take some notes.
Originally, we have an pub/sub system based on redis(use BLPOP to listen to a redis list). It&amp;rsquo;s really simple, and mainly for cross app operations. Now we have needs to enhance it to support more complex pubsub logic, eg: topic based distribution. It don&amp;rsquo;t support redelivery as well, if subscribers failed to process the message, message will be dropped.</description>
    </item>
    
    <item>
      <title>Migrate to Sqlalchemy</title>
      <link>https://blog.monsterxx03.com/2018/05/20/migrate-to-sqlalchemy/</link>
      <pubDate>Sun, 20 May 2018 15:11:31 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/05/20/migrate-to-sqlalchemy/</guid>
      <description>最近把公司 db 层的封装代码基于 sqlalchemy 重写了, 记录一些.
原来的 db 层代码历史非常古老(10年以上&amp;hellip;), 最早写代码的人早就不在了, 问题很多:
 完全没有单元测试. 暴露出的接口命名很混乱, 多数是为了兼容一些历史问题. 里面带一套 client 端 db sharding 的逻辑, 但在新项目里完全用不到, 还导致无法做 join, 无法子查询, 很不方便. 老的 db 代码没有 model 层, 和 db migration 通过一种很 trick 的方式绑定在一起实现的, 导致开发时候对着代码完全无法知道数据库表结构，只能直接看数据库.  重写时候要考虑到的:
 现有业务代码基于老 db 代码已经写了很多了, 重写不现实, 迁移到 sqlalchemy 需要封装一套完全兼容的 api, 没用到的混乱的老 api 趁机清理. db migration 需要重新实现, 只用 alembic 不能满足需求, 后详. 重写完的代码保证高测试覆盖率.  ORM or Core sqlalchemy 分成两部分, 底层的 sqlalchemy core 是一套 sql 语法生成器, 通过重载 python 的 magic function 实现用比较漂亮的 python 语法来构造 sql.</description>
    </item>
    
    <item>
      <title>AWS 的 K8S CNI Plugin</title>
      <link>https://blog.monsterxx03.com/2018/04/09/aws-%E7%9A%84-k8s-cni-plugin/</link>
      <pubDate>Mon, 09 Apr 2018 15:28:38 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/04/09/aws-%E7%9A%84-k8s-cni-plugin/</guid>
      <description>EKS 还没有 launch, 但 AWS 先开源了自己的 CNI 插件, 简单看了下, 说说它的实现和其他 K8S 网络方案的差别.
K8S 集群对网络有几个基本要求:
 container 之间网络必须可达，且不通过 NAT 所有 node 必须可以和所有 container 通信, 且不通过 NAT container 自己看到的 IP, 必须和其他 container 看到的它的 ip 相同.  Flannel in VPC flannel 是 K8S 的一个 CNI 插件, 在 VPC 里使用 flannel 的话, 有几个选择:
 通过 VXLAN/UDP 进行封包, 封包影响网络性能, 而且不好 debug 用 aws vpc backend, 这种方式会把每台主机的 docker 网段添加进 vpc routing table, 但默认 routing table 里只能有50条规则, 所以只能 50 个 node, 可以发 ticket 提升, 但数量太多会影响 vpc 性能.</description>
    </item>
    
    <item>
      <title>AWS lambda 的一些应用场景</title>
      <link>https://blog.monsterxx03.com/2018/03/23/aws-lambda-%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Fri, 23 Mar 2018 17:40:54 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/03/23/aws-lambda-%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid>
      <description>这几年吹 serverless 的比较多, 在公司内部也用 lambda , 记录一下, 这东西挺有用, 但远不到万能, 场景比较有限.
lambda 的代码的部署用的 serverless 框架, 本身支持多种 cloud 平台, 我们就只在 aws lambda 上了.
我基本上就把 lambda 当成 trigger 和 web hook 用.
和 auto scaling group 一起用 线上所有分组的机器都是用 auto scaling group 管理的, 只不过 stateless 的 server 开了自动伸缩, 带状态的 (ElasticSearch cluster, redis cache cluster) 只用来维护固定 size.
在往一个 group 里加 server 的时候, 要做的事情挺多的, 给新 server 添加组内编号 tag, 添加内网域名, provision, 部署最新代码.
这些事都用 jenkins 来做, 但怎么触发 jenkins job 呢?</description>
    </item>
    
    <item>
      <title>一次失败的性能问题排查</title>
      <link>https://blog.monsterxx03.com/2018/03/17/%E4%B8%80%E6%AC%A1%E5%A4%B1%E8%B4%A5%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</link>
      <pubDate>Sat, 17 Mar 2018 14:24:33 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/03/17/%E4%B8%80%E6%AC%A1%E5%A4%B1%E8%B4%A5%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</guid>
      <description>一叶障目, 不见泰山. 前阵子一直在排查一个性能问题, 结果由于一些惯性思维, 费了好大劲才弄明白原因, 而且原因非常简单&amp;hellip;.把这事记录下来,免得以后再掉坑里去.
现象是到了晚上10点多, server lantency 突然一瞬间变高, 但持续时间很短，马上就会恢复, timeout 的请求也不多，影响不大.问题其实从蛮久前就出现了, 但一直也没很重视, 因为持续时间短,影响也不大,简单看了下也没看出明显的问题, 就一直搁置着. 直到最近，觉得问题变严重了, latency 变的更高了，而且在10～11点间多次变高, 开始认真看为什么.
以下是 debug 过程:
 时间段非常固定，每天的晚上10 ~ 11点之间, 每次持续时间很短, 触发时间不是很有规律. 查看那段时间每个 group 的 load 情况, 有变高,但不明显. 查看 qps, 并没显著变化. 查看 qps * avg_latency, 可以看到在一段时间内最耗时的接口, 只能看到几乎所有接口都变高了, 占比最高的还是那几个最慢的接口, 并不能解释突发的 latency 变化.  开始推测, 晚上的 10 点到 11 点,美国那边用户差不多起床,是每天第一次打开 app 的时候, 而我们有些接口里很慢的 code path 只有用户在一天内第一次使用 app 的时候才会触发, 那边的业务逻辑本来就很混乱, 开始着手优化业务代码.
 看 datadog 的 apm tracing, 查看慢接口对各种 service 的调用情况 (Redis, MySQL, ElasticSearch,DynamoDB&amp;hellip;) 通过 pyflame 抓取进程运行时的 stack trace.</description>
    </item>
    
    <item>
      <title>Access sensitive variables on AWS lambda</title>
      <link>https://blog.monsterxx03.com/2018/02/28/access-sensitive-variables-on-aws-lambda/</link>
      <pubDate>Wed, 28 Feb 2018 21:45:23 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/02/28/access-sensitive-variables-on-aws-lambda/</guid>
      <description>AWS lambda is convenient to run simple serverless application, but how to access sensitive data in code? like password,token&amp;hellip;
Usually, we inject secrets as environment variables, but they&amp;rsquo;re still visable on lambda console. I don&amp;rsquo;t use it in aws lambda.
The better way is use aws parameter store as configuration center. It can work with KMS to encrypt your data.
Code example:
client = boto3.client(&#39;ssm&#39;) resp = client.get_parameter( Name=&#39;/redshift/admin/password&#39;, WithDecryption=True ) resp: { &amp;quot;Parameter&amp;quot;: { &amp;quot;Name&amp;quot;: &amp;quot;/redshift/admin/password&amp;quot;, &amp;quot;Type&amp;quot;: &amp;quot;SecureString&amp;quot;, &amp;quot;Value&amp;quot;: &amp;quot;password value&amp;quot;, &amp;quot;Version&amp;quot;: 1 } }  Things you need to do to make it work:</description>
    </item>
    
    <item>
      <title>用 google spreadsheet 计算房贷等额本息还款</title>
      <link>https://blog.monsterxx03.com/2018/02/25/%E7%94%A8-google-spreadsheet-%E8%AE%A1%E7%AE%97%E6%88%BF%E8%B4%B7%E7%AD%89%E9%A2%9D%E6%9C%AC%E6%81%AF%E8%BF%98%E6%AC%BE/</link>
      <pubDate>Sun, 25 Feb 2018 13:59:11 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/02/25/%E7%94%A8-google-spreadsheet-%E8%AE%A1%E7%AE%97%E6%88%BF%E8%B4%B7%E7%AD%89%E9%A2%9D%E6%9C%AC%E6%81%AF%E8%BF%98%E6%AC%BE/</guid>
      <description>看房看的眼花缭乱, 网上有很多房贷计算器, 但都没什么方便的比价功能, 能直观得看到首付和月供就好啦, 但也不想注册，不想老收中介的广告,索性用 google spreadsheet 自己做个简单的吧.
PMT 公式 可以用 PMT 公式来计算等额本息的月供金额: https://support.google.com/docs/answer/3093185?hl=zh-Hans
PMT(rate, number_of_periods, present_value, [future_value, end_or_beginning])  rate 是每期的利率, 如果商贷基准利率是 0.049, 每月还款, rate 就是 0.049/12.
number_of_periods 是贷款期数, 年数 * 12.
present_value 是贷款数额.
PMT 公式算出的值是负数，需要取反.
实际例子:
商贷基准利率=0.049 利率倍数=1 首付百分比=0.3 贷款年数=30 公积金贷款利率=0.0325 公积金贷款数额=300000 房产单价=14000 建筑面积=85  房屋总价=14000 * 85=1190000 首付= 1190000 * 0.3 = 357000 商贷=1190000-357000-300000=533000
月供= -PMT(0.049/12 * 1, 30*12, 533000) - PMT(0.0325/12, 30 * 12, 300000) =4134</description>
    </item>
    
    <item>
      <title>Glow Infra Evolution</title>
      <link>https://blog.monsterxx03.com/2018/02/23/glow-infra-evolution/</link>
      <pubDate>Fri, 23 Feb 2018 23:25:13 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/02/23/glow-infra-evolution/</guid>
      <description>Glow data infrastructure 的演化 Glow 一向是一个 data driven 做决策的公司，稳定高效的平台是必不可少的支撑, 本文总结几年里公司 data infrastructure 的演进过程.
结合业务特点做技术选型和实现时候的几个原则:
 real time 分析的需求不高，时间 delta 控制在1 小时以内可接受 . 支持快速的交互式查询. 底层平台尽量选择 AWS 托管服务, 减少维护成本. 遇到故障, 数据可以 delay 但不能丢. 可回溯历史数据. 成本可控.  用到的 AWS 服务:
 数据存储和查询: S3, Redshift (spectrum), Athena ETL: DMS, EMR, Kinesis, Firehose, Lambda  开源软件: td-agent, maxwell
数据来源:
 线上业务数据库 用户活动产生的 metrics log 从各种第三方服务 api 拉下来的数据 (email之类)  最早期 刚开始的时候业务单纯，数据量也少, 所有数据都用 MySQL 存储，搭了台 slave, 分析查询都在 slave 上进行.</description>
    </item>
    
    <item>
      <title>Get Real Client Ip on AWS</title>
      <link>https://blog.monsterxx03.com/2018/02/01/get-real-client-ip-on-aws/</link>
      <pubDate>Thu, 01 Feb 2018 15:20:37 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/02/01/get-real-client-ip-on-aws/</guid>
      <description>If you run a webserver on AWS, get real client ip will be tricky if you didn&amp;rsquo;t configure server right and write code correctly.
Things related to client real ip:
 CloudFront (cdn) ALB (loadbalancer) nginx (on ec2) webserver (maybe a python flask application).  Request sequence diagram will be like following:
User&amp;rsquo;s real client ip is forwarded by front proxies one by one in head X-Forwarded-For.
For CloudFront:
 If user&amp;rsquo;s req header don&amp;rsquo;t have X-Forwarded-For, it will set user&amp;rsquo;s ip(from tcp connection) in X-Forwarded-For If user&amp;rsquo;s req already have X-Forwarded-For, it will append user&amp;rsquo;s ip(from tcp connection) to the end of X-Forwarded-For  For ALB, rule is same as CloudFront, so the X-Forwarded-For header pass to nginx will be the value received from CloudFront + CloudFront&amp;rsquo;s ip.</description>
    </item>
    
    <item>
      <title>DynamoDB</title>
      <link>https://blog.monsterxx03.com/2017/12/15/dynamodb/</link>
      <pubDate>Fri, 15 Dec 2017 22:24:36 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/12/15/dynamodb/</guid>
      <description>DynamoDB 是 AWS 的托管 NoSQL 数据库，可以当作简单的 KV 数据库使用，也可以作为文档数据库使用.
Data model 组织数据的单位是 table, 每张 table 必须设置 primary key, 可以设置可选的 sort key 来做索引.
每条数据记作一个 item, 每个 item 含有一个或多个 attribute, 其中必须包括 primary key.
attribute 对应的 value 支持以下几种类型:
 Number, 由于 DynamoDB 的传输协议是 http + json, 为了跨语言的兼容性, number 一律会被转成 string 传输. Binary, 用来表示任意的二进制数据，会用 base64 encode 后传输. Boolean, true or false Null Document 类型包含 List 和 Map, 可以互相嵌套.  List, 个数无限制, 总大小不超过 400KB Map, 属性个数无限制，总大小不超过 400 KB, 嵌套层级不超过 32 级.</description>
    </item>
    
    <item>
      <title>Handle outage</title>
      <link>https://blog.monsterxx03.com/2017/12/10/handle-outage/</link>
      <pubDate>Sun, 10 Dec 2017 11:13:53 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/12/10/handle-outage/</guid>
      <description>A few weeks ago, production environment came to an outage, solve it cost me 8 hours (from 3am to 11am) although total down time is not long, really a bad expenrience. Finally, impact was mitigated, and I&amp;rsquo;m working on a long term solution. I learned some important things from this accident.
The outage I received alarms about live performance issue at 3am, first is server latency increaing, soon some service&amp;rsquo;s health check failed due to high load.</description>
    </item>
    
    <item>
      <title>AWS DMS notes</title>
      <link>https://blog.monsterxx03.com/2017/10/14/aws-dms-notes/</link>
      <pubDate>Sat, 14 Oct 2017 22:33:36 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/10/14/aws-dms-notes/</guid>
      <description>AWS&amp;rsquo;s DMS (Data migration service) can be used to do incremental ETL between databases. I use it to load data from RDS (MySQL) to Redshift.
It works, but have some concerns. Take some notes when doing this project.
Prerequisites Source RDS must:
 Enable automatic backups Increase binlog remain time, call mysql.rds_set_configuration(&#39;binlog retention hours&#39;, 24); Set binlog_format to ROW. Privileges on source RDS: REPLICATION CLIENT, REPLICATION SLAVE, SELECT on replication target tables  DDL on source table Redshift has some limits on change columns:</description>
    </item>
    
    <item>
      <title>Get all invalid PTR record on  Route53</title>
      <link>https://blog.monsterxx03.com/2017/09/29/get-all-invalid-ptr-record-on-route53/</link>
      <pubDate>Fri, 29 Sep 2017 08:55:18 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/09/29/get-all-invalid-ptr-record-on-route53/</guid>
      <description>I use autoscaling group to manage stateless servers. Servers go up and down every day.
Once server is up, I will add a PTR record for it&amp;#8217;s internal ip. But when it&amp;#8217;s down, I didn&amp;#8217;t cleanup the PTR record. As times fly, a lot of invalid PTR records left in Route53.
To cleanup those PTR records realtime, you can write a lambda function, use server termination event as trigger. But how to cleanup the old records at once?</description>
    </item>
    
    <item>
      <title>Build private static website on S3</title>
      <link>https://blog.monsterxx03.com/2017/08/19/build-private-staticwebsite-on-s3/</link>
      <pubDate>Sat, 19 Aug 2017 07:28:16 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/08/19/build-private-staticwebsite-on-s3/</guid>
      <description>Build static website on S3 is very easy, but by default, it can be accessed by open internet.It will be super helpful if we can build website only available in VPC. Then we can use it to host internal deb repo, doc site&amp;#8230;
Steps are very easy, you only need VPC endpoints and S3 bucket policy.
AWS api is open to internet, if you need to access S3 in VPC, your requests will pass through VPC&amp;#8217;s internet gateway or NAT gateway.</description>
    </item>
    
    <item>
      <title>旅行散记</title>
      <link>https://blog.monsterxx03.com/2017/08/13/%E6%97%85%E8%A1%8C%E6%95%A3%E8%AE%B0/</link>
      <pubDate>Sun, 13 Aug 2017 15:18:52 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/08/13/%E6%97%85%E8%A1%8C%E6%95%A3%E8%AE%B0/</guid>
      <description>前阵子总有点心烦意乱的，生活上的，家里的，堵在一块，弄得自己都有点疲惫了，8月初的时候去日本东北逛了一圈，恰逢当地祭奠密集期，也就凑了把热闹，还挺有意思。
行程: 上海 -&amp;gt; 东京 -&amp;gt; 盛冈 -&amp;gt; 八户 -&amp;gt; 十和田湖 -&amp;gt; 青森 -&amp;gt; 弘前 -&amp;gt; 东京 -&amp;gt; 上海, 满满当当的7天, 懒得贴图，瞎记一点。
盛冈是岩手县的首府，但刚到的时候感觉真是个大乡下啊，大白天，出了车站区域，步行1公里多的时间里只碰到了2个人，一个桥下睡觉的大叔，一个遛狗的，像个鬼城似的，超级不习惯。到了晚上，当地有三飒舞祭典，一下子不知从哪冒出来好多人。大家聚在一起，各种路边摊买买买，吃吃吃，热闹的不敢相信是白天那个城市。三飒舞是当地一种传统舞蹈(传说是为了封印一个什么鬼的)，一边跳一边前进，有的打太鼓，有的吹笛，有的空手，跳的专业的还挺好看的，也有很多充数的小盆友啦:). 参加的都是当地一些团体和企业，基本就当是一次大型广告巡游, 当打太鼓的方阵经过面前的时候，气势还是很震撼的。在盛冈呆了两天，从刚到的不适应一下变得相当享受那里的城市氛围, 城市里到处都是风铃和紫阳花，闲适的生活，第一次这么向往在一个城市生活。
八户这个相对来说就没那么多感觉了，靠海边比较近，海风很舒服，但很多建筑都破破烂烂的，风化很严重，住的酒店也是破破烂烂的，在那边看了一个八户三社大祭，是当地三个神社联合举办的夏日祭典。前面是各种穿着传统服装的游行队伍，后面是一座座装扮华丽的花车，啊啊啊，看到了超可爱的小萝莉, 还有很有趣的日本矮种马，超mini，还不太听话，几个人硬拽着才肯往前走。
去八户的时候，坐过头，到了一个叫鲛(日语shame, 鲨鱼的意思)的小镇，瞬间觉得这才是真乡下. 除了海鸥和鱼一无所有，连个饭馆都没找到，费老大劲找到了镇上唯一一个超市，买到了个可乐饼充饥，车站里贴着的通缉令还是十几年前的，时间好像在这个小镇上凝固了。在车站等车的时候，看着那个小小的车站，突然明白了为什么日本有那么多的铁道宅，他们又是为什么对铁路文化那么痴迷。顺着蜿蜒的铁轨朝远处看去，除了山和云，就是草，这和在东京那种大城市的站头真是完全不同的感觉。
在八户只呆了一晚，主要是为了第二天去十和田湖的。坐大巴在石之户下了车，吃了碗拉面准备步行14公里到十和田湖。传说石之户那里，在古代有美女盗贼沿途打劫男性，想想有点小激动呢,哈哈。去十和田湖的这段路叫奥入濑溪流，也是个有名的景点，没有国内那种大山大河的开阔景色，未经人工修饰的风景却相当有日本那种传统的禅意, 夏天绿油油的，估计在红叶季节应该相当美。
十和田湖是个火山湖，水质很清，云很漂亮，值得一去。就是在那边住宿的时候很不愉快，因为酒店定的晚了，只能定背包客栈的床位，结果是和一家子韩国人5个一间房，好崩溃，一家人都超级没有礼貌的，打招呼根本不鸟我。晚上一家人的奶奶大呼声音超可怕，我被吵得睡不着，索性跑到旅馆大厅通宵看书。看了会走过来个日本大叔，英语很棒，瞎聊了一句，话题基本集中在安倍是个sb，福岛很不妙啊巴拉巴拉，还是个很不错的大叔，期间他的一个伙伴跑过来偷偷在桌子角上贴了张自己做的贴纸，叮嘱我千万别告诉老板是他干的，有意思。他们走后，不久老板来巡夜，知道我被吵得睡不着后，带我去了special room! 在放杂物的房间里尽然有床铺，感动！老板您真的超级nice啊。
在青森没定到酒店，住在了弘前一家有200年历史的旅馆里，很传统的日式旅馆，房子很老，但体验很不错，唯一纠结的就是泡澡的话我是应该把水放掉还是留着给下个人呢，实在吃不准，结果就洗了个淋浴。弘前和青森都有睡魔祭，也是花车，不过是带灯的，所以是晚上开始。弘前人的热情更有感染力，青森的花车赞助比较多，所以更壮观一点:).弘前有个吉祥物鹰丸君，本来头上戴的是弘前城的天守阁，因为天守现在在翻修，变成了头上戴安全帽，也是有意思。青森车站旁边有个A factory, 里面有很多苹果制特产，值得一逛，要不是只有一个背包，真的想塞好多东西回来。
都说东北经济不行，年轻人都往东京跑啦，在那边几天，确实感觉白天没有东京的那种商业氛围。但他们的祭典感染力真的超强，就我这么一个瞎跑过去凑热闹的家伙也能看得情绪高涨，一年一次的祭典，真的变成了凝聚当地居民的一种仪式，一家人坐在路边，撸串喝啤酒，看游行，真的好羡慕，这样的场景，在国内怎样都不会有哎。</description>
    </item>
    
    <item>
      <title>Use redshift spectrum to do query on s3</title>
      <link>https://blog.monsterxx03.com/2017/07/21/use-redshift-spectrum-to-do-query-on-s3/</link>
      <pubDate>Fri, 21 Jul 2017 03:10:58 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/07/21/use-redshift-spectrum-to-do-query-on-s3/</guid>
      <description>使用 redshift spectrum 查询 S3 数据 通常使用 redshift 做数据仓库的时候要做大量的 ETL 工作，一般流程是把各种来源的数据捣鼓捣鼓丢到 S3 上去，再从 S3 倒腾进 redshift. 如果你有大量的历史数据要导进 redshift，这个过程就会很痛苦，redshift 对一次倒入大量数据并不友好，你要分批来做。
今年4月的时候， redshift 发布了一个新功能 spectrum, 可以从 redshift 里直接查询 s3 上的结构化数据。最近把部分数据仓库直接迁移到了 spectrum, 正好来讲讲。
动机 Glow 的数据仓库建在 redshift 上， 又分成了两个集群，一个 ssd 的集群存放最近 4 个月的数据，供产品分析，metrics report, debug 等等 adhoc 的查询。4个月之前的数据存放在一个 hdd 的集群里，便宜容量大，查询慢。
但是时间长了 hdd 的集群也是有扩容需求的，而使用频率又实在是不高，其实很浪费, 这就是迁移到 spectrum 的动机。
使用 Spectrum Redshift spectrum 底层其实是基于 AWS 的另一个服务 athena 的。athena 是个 Presto 和 Hive 杂交产物， DDL 用 Hive 语法， 查询用的 sql 由 Presto 支持, 感觉怪怪的，这里不多展开讲 athena, 知道 redshift spectrum 其实是通过 athena 对接的 s3 就行了。</description>
    </item>
    
    <item>
      <title>Enable coredump on ubuntu 16.04</title>
      <link>https://blog.monsterxx03.com/2017/07/15/enable-coredump-on-ubuntu-16.04/</link>
      <pubDate>Sat, 15 Jul 2017 02:35:52 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/07/15/enable-coredump-on-ubuntu-16.04/</guid>
      <description>Coredump file is useful for debuging program crash. This post will show several settings related to coredump.
Enable coredump If you run program from shell , enable coredump via unlimit -c unlimited， then check unlimit -a | grep core, if it shows unlimited, coredump is enabled for your current session.
If your program is hosted by systemd, you need to edit your program&amp;#8217;s service unit file&amp;#8217;s [Service] section, add LimitCORE=infinity to enable coredump.</description>
    </item>
    
    <item>
      <title>Python Web 应用性能调优</title>
      <link>https://blog.monsterxx03.com/2017/07/01/python-web-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</link>
      <pubDate>Sat, 01 Jul 2017 23:38:24 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/07/01/python-web-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</guid>
      <description>Python web 应用性能调优 为了快速上线，早期很多代码基本是怎么方便怎么来，这样就留下了很多隐患，性能也不是很理想，python 因为 GIL 的原因，在性能上有天然劣势，即使用了 gevent/eventlet 这种协程方案，也很容易因为耗时的 CPU 操作阻塞住整个进程。前阵子对基础代码做了些重构，效果显著，记录一些。
设定目标:
 性能提高了，最直接的效果当然是能用更少的机器处理相同流量，目标是关闭 20% 的 stateless webserver. 尽量在框架代码上做改动，不动业务逻辑代码。 低风险 (历史经验告诉我们，动态一时爽，重构火葬场&amp;hellip;.)  治标 常见场景是大家开开心心做完一个 feature， sandbox 测试也没啥问题，上线了，结果 server load 飙升，各种 timeout 都来了，要么 rollback 代码，要么加机器。问题代码在哪?
我们监控用的是 datadog (statsd协议)，对这种问题最有效的指标是看每个接口的 avg_latency * req_count 得到每个接口在一段时间内的总耗时，在柱状图上最长的那块就是对性能影响最大的接口。进一步的调试就靠 cProfile 和读代码了。
但很多时候出问题的代码逻辑巨复杂，还很多人改动过，开发和 sandbox 环境数据的量和线上差距太大，无法复现问题，在线上用 cProfile 只能测只读接口(为了不写坏用户数据)。
而且这种方式只能治标，调试个别慢的业务接口，目标里说了只想改框架，提高整体性能，怎么整?
治本 我希望能对运行时进程状态打 snapshot，每次快照记录下当前的函数调用栈，叠合多次采样，出现次数多的函数必然就是瓶颈所在. 这思想在其他语言里用的也很多，其实就是 Brendan Gregg 的 flamegraph.
以前内部做过类似的事情，不过代码是侵入式的，在运行时通过 signal, inspect, traceback 等模块，定期打调用栈的 snapshot, 输出到文件，转成 svg 的 flamegraph 来看，但是 overhead 太高，后来弃用了。</description>
    </item>
    
    <item>
      <title>Build deb repository with fpm , aptly and s3</title>
      <link>https://blog.monsterxx03.com/2017/06/23/build-deb-repository-with-fpm-aptly-and-s3/</link>
      <pubDate>Fri, 23 Jun 2017 09:40:58 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/06/23/build-deb-repository-with-fpm-aptly-and-s3/</guid>
      <description>I&amp;#8217;m lazy, I don&amp;#8217;t want to be deb/rpm expert, I don&amp;#8217;t want to maintain repo server. I want as less maintenance effort as possible. 🙂
Combine tools fpm, aptly with aws s3, we can do it.
Use fpm to convert python package to deb fpm can transform python/gem/npm/dir/&amp;#8230; to deb/rpm/solaris/&amp;#8230; packages
Example:
fpm -s python -t deb -m xyj.asmy@gmail.com --verbose -v 0.10.1 --python-pip /usr/local/pip Flask  It will transform Flask 0.</description>
    </item>
    
    <item>
      <title>Debug python performance issue with pyflame</title>
      <link>https://blog.monsterxx03.com/2017/06/05/debug-python-performance-issue-with-pyflame/</link>
      <pubDate>Mon, 05 Jun 2017 09:50:44 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/06/05/debug-python-performance-issue-with-pyflame/</guid>
      <description>pyflame is an opensource tool developed by uber: https://github.com/uber/pyflame
It can take snapshots of running python process, combined with flamegraph.pl, can output flamegraph picture of python call stacks. Help analyze bottleneck of python program, needn&amp;#8217;t inject any perf code into your application, and overhead is very low.
Basic Usage sudo pyflame -s 10 -x -r 0.001 $pid | ./flamegraph.pl &amp;gt; perf.svg
 -s, how many seconds to run -r, sample rate (seconds)  Your output will be something like following:</description>
    </item>
    
    <item>
      <title>Designing data intensive application, reading notes, Part 2</title>
      <link>https://blog.monsterxx03.com/2017/05/17/designing-data-intensive-application-reading-notes-part-2/</link>
      <pubDate>Wed, 17 May 2017 09:12:44 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/05/17/designing-data-intensive-application-reading-notes-part-2/</guid>
      <description>Chapter 4, 5, 6
Encoding formats xml, json, msgpack are text based encoding format, they can&amp;#8217;t carry binary bytes (useless you encode them in base64, size grows 33%). And they cary schema definition with data, wast a lot of space.
thrift, protobuf are binary format, can take binary bytes, only carry data, the schema is defined with IDL(interface definition language). They have code generation tool to generate code to encode and decode data, along with check.</description>
    </item>
    
    <item>
      <title>Designing data intensive application, reading notes, Part 1</title>
      <link>https://blog.monsterxx03.com/2017/05/04/designing-data-intensive-application-reading-notes-part-1/</link>
      <pubDate>Thu, 04 May 2017 16:27:52 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/05/04/designing-data-intensive-application-reading-notes-part-1/</guid>
      <description>&lt;p&gt;Notes when reading chapter 2 &amp;#8220;Data models and query languages&amp;#8221;, chapter 3 &amp;#8220;Storage and retrieval&amp;#8221;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>4月周末杂记</title>
      <link>https://blog.monsterxx03.com/2017/04/23/4%E6%9C%88%E5%91%A8%E6%9C%AB%E6%9D%82%E8%AE%B0/</link>
      <pubDate>Sun, 23 Apr 2017 16:26:04 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/23/4%E6%9C%88%E5%91%A8%E6%9C%AB%E6%9D%82%E8%AE%B0/</guid>
      <description>&lt;p&gt;月初的时候搬了家, 之后的周末一直在忙些琐琐碎碎的事情，嘛，仔细一想，除了去宜家搬了个电视柜回来都不记得干了啥&amp;#8230;&lt;/p&gt;

&lt;p&gt;这周末心血来潮去听了两个讲座，一个人文的，一个技术的，还都碰到了点有意思的事情。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Infrastructure as Code</title>
      <link>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</link>
      <pubDate>Fri, 21 Apr 2017 16:25:07 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</guid>
      <description>&lt;p&gt;Create virtual resource on AWS is very convenient, but how to manage them will be a problem when your size grow.&lt;/p&gt;

&lt;p&gt;You will come to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How to explain the detail online settings for your colleagues (like: how our prod vpc is setup?what&amp;#8217;s the DHCP option set?), navigate around AWS console is okay, but not convenient.&lt;/li&gt;
&lt;li&gt;Who did what to which resource at when? AWS have a service called &lt;code&gt;Config&lt;/code&gt;, can be used to track this change, but if you want to make things as clear as viewing git log, still a lot of works to do.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ideally, we should manage AWS resources like code, all changes kept in VCS, so called &lt;code&gt;Infrastructure as Code&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;ve tried three ways to do it:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ansible&lt;/li&gt;
&lt;li&gt;CloudFormation&lt;/li&gt;
&lt;li&gt;terraform&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this article, I&amp;#8217;ll compare them, however, the conclusion is to use terraform 🙂&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Concurrency in Go, Reading Notes</title>
      <link>https://blog.monsterxx03.com/2017/04/19/concurrency-in-go-reading-notes/</link>
      <pubDate>Wed, 19 Apr 2017 16:26:58 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/19/concurrency-in-go-reading-notes/</guid>
      <description>&lt;p&gt;A few notes taken when reading &lt;Concurrency in Go&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MySQL partition table</title>
      <link>https://blog.monsterxx03.com/2017/04/05/mysql-partition-table/</link>
      <pubDate>Wed, 05 Apr 2017 16:23:32 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/05/mysql-partition-table/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;MySQL has buildin partition table support, which can help split data accross multi tables,&lt;/p&gt;

&lt;p&gt;and provide a unified query interface as normal tables.&lt;/p&gt;

&lt;p&gt;Benefit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Easy data management: If we need to archive old data, and our table is partitioned by datetime, we can drop old partition directly.&lt;/li&gt;
&lt;li&gt;Speed up query based on partition key(partitoin pruning)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Limit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For partition table, every unique key must use every column in table&amp;#8217;s partition expression(include primary key)&lt;/li&gt;
&lt;li&gt;For innodb engine, paritioned table can&amp;#8217;t have foreign key,and can&amp;#8217;t have columns referenced by foreign keys.&lt;/li&gt;
&lt;li&gt;For MyISAM engine, mysql version &amp;lt;= 5.6.5, DML operation will lock all partition as a whole.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ElasticSearch cluster</title>
      <link>https://blog.monsterxx03.com/2017/03/22/elasticsearch-cluster/</link>
      <pubDate>Wed, 22 Mar 2017 16:22:32 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/03/22/elasticsearch-cluster/</guid>
      <description>&lt;p&gt;In this article, let&amp;#8217;s talk about ElasticSearch&amp;#8217;s cluster mode, which means multi nodes ElasticSearch.&lt;/p&gt;

&lt;h2 id=&#34;basic-concepts&#34;&gt;Basic concepts&lt;/h2&gt;

&lt;p&gt;cluster: A collection of server nodes with same &lt;code&gt;cluster.name&lt;/code&gt; settings in elasticsearch.yaml&lt;/p&gt;

&lt;p&gt;primary shards: Divide a index into multi parts(by default 5), shards of an index can be distributed over multi nodes. It enables scale index horizontally and make access to index parallelly(accross multi nodes).&lt;/p&gt;

&lt;p&gt;replicas: backup for shards, also replicas can handle search requests, which means you can scale your search capacity horizontally via replicas.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Matrix 14 years later</title>
      <link>https://blog.monsterxx03.com/2017/03/11/matrix-14-years-later/</link>
      <pubDate>Sat, 11 Mar 2017 16:21:31 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/03/11/matrix-14-years-later/</guid>
      <description>&lt;p&gt;心血来潮, 又看了遍黑客帝国三部曲, 当年的沃卓斯基兄弟都变成沃卓斯基姐妹了, 唏嘘啊&amp;#8230;&lt;/p&gt;

&lt;p&gt;第一次看的时候, 好像是初中吧, 记得看第三部还是姑父的盗版碟上看的, 那天还拉了个同学和我一起看,然后请他吃了泡面+冰淇淋,结果他回家就拉肚了,抱怨了我好久,所以印象特别深刻,哈哈.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bigtable notes</title>
      <link>https://blog.monsterxx03.com/2016/12/11/bigtable-notes/</link>
      <pubDate>Sun, 11 Dec 2016 16:20:24 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/12/11/bigtable-notes/</guid>
      <description>&lt;p&gt;杂乱笔记，辅助读paper.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GFS notes</title>
      <link>https://blog.monsterxx03.com/2016/11/19/gfs-notes/</link>
      <pubDate>Sat, 19 Nov 2016 16:18:41 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/11/19/gfs-notes/</guid>
      <description>&lt;p&gt;看了下很久前 google 的 GFS 论文， 做点笔记。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migrate to encrypted RDS</title>
      <link>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</link>
      <pubDate>Fri, 28 Oct 2016 16:17:30 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</guid>
      <description>&lt;p&gt;最近公司在做 HIPAA Compliance 相关的事情，其中要求之一是所有db需要开启encryption.&lt;/p&gt;

&lt;p&gt;比较麻烦的是rds 的encryption 只能在创建的时候设定，无法之后修改, 所以必须对线上的db 做一次 migration.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>魔法使</title>
      <link>https://blog.monsterxx03.com/2016/08/06/witch-night/</link>
      <pubDate>Sat, 06 Aug 2016 16:16:23 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/08/06/witch-night/</guid>
      <description>&lt;p&gt;最近心血来潮把&amp;lt;魔法使之夜&amp;gt;的游戏通关了, 都已经是5年?还是6年前发售的了, 因为当年汉化迟迟不发布, 就一直搁置了.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MySQL 索引优化</title>
      <link>https://blog.monsterxx03.com/2016/07/26/mysql-index-optimization/</link>
      <pubDate>Tue, 26 Jul 2016 16:13:54 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/07/26/mysql-index-optimization/</guid>
      <description>&lt;p&gt;什么是索引,索引怎么建这些基本的就跳过不谈了,整理一些前段时间优化线上 SQL 查询时碰到的一些问题. 主要解决下面几个问题:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;建立索引怎样选择合适的列.&lt;/li&gt;
&lt;li&gt;怎样让 SQL 能有效利用索引.&lt;/li&gt;
&lt;li&gt;如果对 SQL 效率进行评估(即设置索引前后是否真的有性能提升).&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Redshift as data warehouse</title>
      <link>https://blog.monsterxx03.com/2016/07/16/redshift-as-data-warehouse/</link>
      <pubDate>Sat, 16 Jul 2016 16:11:39 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/07/16/redshift-as-data-warehouse/</guid>
      <description>&lt;p&gt;Glow 的 server infrastructure 全部搭建在 AWS 上，一般要选择一些基础服务的时候，总是先看 AWS, 只要功能和成本符合要求，不会特意选择开源方案。&lt;/p&gt;

&lt;p&gt;数据仓库我们选择了 AWS 的 Redshift.&lt;/p&gt;

&lt;p&gt;在一年多的使用过程中 Redshift 的性能和稳定性都不错, 当然也有一些坑, 这里整理下在使用 redshift 的过程中的一些经验和遇到的坑.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MySQL innodb buffer pool</title>
      <link>https://blog.monsterxx03.com/2016/07/16/mysql-innodb-buffer-pool/</link>
      <pubDate>Sat, 16 Jul 2016 16:07:14 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/07/16/mysql-innodb-buffer-pool/</guid>
      <description>&lt;p&gt;最近在对公司的 MySQL 服务器做性能优化, 一直对 innodb 的内存使用方式不是很清楚, 乘这机会做点总结.&lt;/p&gt;

&lt;p&gt;在配置 MySQL 的时候, 一般都会需要设置 _innodb_buffer_pool&lt;em&gt;size&lt;/em&gt;, 在将 MySQL 设置在单独的服务器上时, 一般会设置为物理内存的80%.&lt;/p&gt;

&lt;p&gt;之前一直疑惑 MySQL 是怎么缓存数据的(不是指query cache), 直觉应该是LRU, 但如果 query 一下从磁盘上读取大量的数据的话(全表扫描或是 mysqldump), 是不是很容易就会把热数据给踢出去?&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>