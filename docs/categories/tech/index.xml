<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tech on Shining Moon</title>
    <link>https://blog.monsterxx03.com/categories/tech/</link>
    <description>Recent content in Tech on Shining Moon</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>monsterxx03</copyright>
    <lastBuildDate>Wed, 28 Feb 2018 21:45:23 +0800</lastBuildDate>
    
	<atom:link href="https://blog.monsterxx03.com/categories/tech/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Access sensitive variables on AWS lambda</title>
      <link>https://blog.monsterxx03.com/2018/02/28/access-sensitive-variables-on-aws-lambda/</link>
      <pubDate>Wed, 28 Feb 2018 21:45:23 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/02/28/access-sensitive-variables-on-aws-lambda/</guid>
      <description>AWS lambda is convenient to run simple serverless application, but how to access sensitive data in code? like password,token&amp;hellip;
Usually, we inject secrets as environment variables, but they&amp;rsquo;re still visable on lambda console. I don&amp;rsquo;t use it in aws lambda.
The better way is use aws parameter store as configuration center. It can work with KMS to encrypt your data.
Code example:
client = boto3.client(&#39;ssm&#39;) resp = client.get_parameter( Name=&#39;/redshift/admin/password&#39;, WithDecryption=True ) resp: { &amp;quot;Parameter&amp;quot;: { &amp;quot;Name&amp;quot;: &amp;quot;/redshift/admin/password&amp;quot;, &amp;quot;Type&amp;quot;: &amp;quot;SecureString&amp;quot;, &amp;quot;Value&amp;quot;: &amp;quot;password value&amp;quot;, &amp;quot;Version&amp;quot;: 1 } }  Things you need to do to make it work:</description>
    </item>
    
    <item>
      <title>Glow Infra Evolution</title>
      <link>https://blog.monsterxx03.com/2018/02/23/glow-infra-evolution/</link>
      <pubDate>Fri, 23 Feb 2018 23:25:13 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/02/23/glow-infra-evolution/</guid>
      <description>Glow data infrastructure 的演化 Glow 一向是一个 data driven 做决策的公司，稳定高效的平台是必不可少的支撑, 本文总结几年里公司 data infrastructure 的演进过程.
结合业务特点做技术选型和实现时候的几个原则:
 real time 分析的需求不高，时间 delta 控制在1 小时以内可接受 . 支持快速的交互式查询. 底层平台尽量选择 AWS 托管服务, 减少维护成本. 遇到故障, 数据可以 delay 但不能丢. 可回溯历史数据. 成本可控.  用到的 AWS 服务:
 数据存储和查询: S3, Redshift (spectrum), Athena ETL: DMS, EMR, Kinesis, Firehose, Lambda  开源软件: td-agent, maxwell
数据来源:
 线上业务数据库 用户活动产生的 metrics log 从各种第三方服务 api 拉下来的数据 (email之类)  最早期 刚开始的时候业务单纯，数据量也少, 所有数据都用 MySQL 存储，搭了台 slave, 分析查询都在 slave 上进行.</description>
    </item>
    
    <item>
      <title>Get Real Client Ip on AWS</title>
      <link>https://blog.monsterxx03.com/2018/02/01/get-real-client-ip-on-aws/</link>
      <pubDate>Thu, 01 Feb 2018 15:20:37 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2018/02/01/get-real-client-ip-on-aws/</guid>
      <description>If you run a webserver on AWS, get real client ip will be tricky if you didn&amp;rsquo;t configure server right and write code correctly.
Things related to client real ip:
 CloudFront (cdn) ALB (loadbalancer) nginx (on ec2) webserver (maybe a python flask application).  Request sequence diagram will be like following:
User&amp;rsquo;s real client ip is forwarded by front proxies one by one in head X-Forwarded-For.
For CloudFront:
 If user&amp;rsquo;s req header don&amp;rsquo;t have X-Forwarded-For, it will set user&amp;rsquo;s ip(from tcp connection) in X-Forwarded-For If user&amp;rsquo;s req already have X-Forwarded-For, it will append user&amp;rsquo;s ip(from tcp connection) to the end of X-Forwarded-For  For ALB, rule is same as CloudFront, so the X-Forwarded-For header pass to nginx will be the value received from CloudFront + CloudFront&amp;rsquo;s ip.</description>
    </item>
    
    <item>
      <title>DynamoDB</title>
      <link>https://blog.monsterxx03.com/2017/12/15/dynamodb/</link>
      <pubDate>Fri, 15 Dec 2017 22:24:36 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/12/15/dynamodb/</guid>
      <description>DynamoDB 是 AWS 的托管 NoSQL 数据库，可以当作简单的 KV 数据库使用，也可以作为文档数据库使用.
Data model 组织数据的单位是 table, 每张 table 必须设置 primary key, 可以设置可选的 sort key 来做索引.
每条数据记作一个 item, 每个 item 含有一个或多个 attribute, 其中必须包括 primary key.
attribute 对应的 value 支持以下几种类型:
 Number, 由于 DynamoDB 的传输协议是 http + json, 为了跨语言的兼容性, number 一律会被转成 string 传输. Binary, 用来表示任意的二进制数据，会用 base64 encode 后传输. Boolean, true or false Null Document 类型包含 List 和 Map, 可以互相嵌套.  List, 个数无限制, 总大小不超过 400KB Map, 属性个数无限制，总大小不超过 400 KB, 嵌套层级不超过 32 级.</description>
    </item>
    
    <item>
      <title>Handle outage</title>
      <link>https://blog.monsterxx03.com/2017/12/10/handle-outage/</link>
      <pubDate>Sun, 10 Dec 2017 11:13:53 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/12/10/handle-outage/</guid>
      <description>A few weeks ago, production environment came to an outage, solve it cost me 8 hours (from 3am to 11am) although total down time is not long, really a bad expenrience. Finally, impact was mitigated, and I&amp;rsquo;m working on a long term solution. I learned some important things from this accident.
The outage I received alarms about live performance issue at 3am, first is server latency increaing, soon some service&amp;rsquo;s health check failed due to high load.</description>
    </item>
    
    <item>
      <title>AWS DMS notes</title>
      <link>https://blog.monsterxx03.com/2017/10/14/aws-dms-notes/</link>
      <pubDate>Sat, 14 Oct 2017 22:33:36 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/10/14/aws-dms-notes/</guid>
      <description>AWS&amp;rsquo;s DMS (Data migration service) can be used to do incremental ETL between databases. I use it to load data from RDS (MySQL) to Redshift.
It works, but have some concerns. Take some notes when doing this project.
Prerequisites Source RDS must:
 Enable automatic backups Increase binlog remain time, call mysql.rds_set_configuration(&#39;binlog retention hours&#39;, 24); Set binlog_format to ROW. Privileges on source RDS: REPLICATION CLIENT, REPLICATION SLAVE, SELECT on replication target tables  DDL on source table Redshift has some limits on change columns:</description>
    </item>
    
    <item>
      <title>Get all invalid PTR record on  Route53</title>
      <link>https://blog.monsterxx03.com/2017/09/29/get-all-invalid-ptr-record-on-route53/</link>
      <pubDate>Fri, 29 Sep 2017 08:55:18 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/09/29/get-all-invalid-ptr-record-on-route53/</guid>
      <description>I use autoscaling group to manage stateless servers. Servers go up and down every day.
Once server is up, I will add a PTR record for it&amp;#8217;s internal ip. But when it&amp;#8217;s down, I didn&amp;#8217;t cleanup the PTR record. As times fly, a lot of invalid PTR records left in Route53.
To cleanup those PTR records realtime, you can write a lambda function, use server termination event as trigger. But how to cleanup the old records at once?</description>
    </item>
    
    <item>
      <title>Build private static website on S3</title>
      <link>https://blog.monsterxx03.com/2017/08/19/build-private-staticwebsite-on-s3/</link>
      <pubDate>Sat, 19 Aug 2017 07:28:16 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/08/19/build-private-staticwebsite-on-s3/</guid>
      <description>Build static website on S3 is very easy, but by default, it can be accessed by open internet.It will be super helpful if we can build website only available in VPC. Then we can use it to host internal deb repo, doc site&amp;#8230;
Steps are very easy, you only need VPC endpoints and S3 bucket policy.
AWS api is open to internet, if you need to access S3 in VPC, your requests will pass through VPC&amp;#8217;s internet gateway or NAT gateway.</description>
    </item>
    
    <item>
      <title>Use redshift spectrum to do query on s3</title>
      <link>https://blog.monsterxx03.com/2017/07/21/use-redshift-spectrum-to-do-query-on-s3/</link>
      <pubDate>Fri, 21 Jul 2017 03:10:58 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/07/21/use-redshift-spectrum-to-do-query-on-s3/</guid>
      <description>使用 redshift spectrum 查询 S3 数据 通常使用 redshift 做数据仓库的时候要做大量的 ETL 工作，一般流程是把各种来源的数据捣鼓捣鼓丢到 S3 上去，再从 S3 倒腾进 redshift. 如果你有大量的历史数据要导进 redshift，这个过程就会很痛苦，redshift 对一次倒入大量数据并不友好，你要分批来做。
今年4月的时候， redshift 发布了一个新功能 spectrum, 可以从 redshift 里直接查询 s3 上的结构化数据。最近把部分数据仓库直接迁移到了 spectrum, 正好来讲讲。
动机 Glow 的数据仓库建在 redshift 上， 又分成了两个集群，一个 ssd 的集群存放最近 4 个月的数据，供产品分析，metrics report, debug 等等 adhoc 的查询。4个月之前的数据存放在一个 hdd 的集群里，便宜容量大，查询慢。
但是时间长了 hdd 的集群也是有扩容需求的，而使用频率又实在是不高，其实很浪费, 这就是迁移到 spectrum 的动机。
使用 Spectrum Redshift spectrum 底层其实是基于 AWS 的另一个服务 athena 的。athena 是个 Presto 和 Hive 杂交产物， DDL 用 Hive 语法， 查询用的 sql 由 Presto 支持, 感觉怪怪的，这里不多展开讲 athena, 知道 redshift spectrum 其实是通过 athena 对接的 s3 就行了。</description>
    </item>
    
    <item>
      <title>Enable coredump on ubuntu 16.04</title>
      <link>https://blog.monsterxx03.com/2017/07/15/enable-coredump-on-ubuntu-16.04/</link>
      <pubDate>Sat, 15 Jul 2017 02:35:52 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/07/15/enable-coredump-on-ubuntu-16.04/</guid>
      <description>Coredump file is useful for debuging program crash. This post will show several settings related to coredump.
Enable coredump If you run program from shell , enable coredump via unlimit -c unlimited， then check unlimit -a | grep core, if it shows unlimited, coredump is enabled for your current session.
If your program is hosted by systemd, you need to edit your program&amp;#8217;s service unit file&amp;#8217;s [Service] section, add LimitCORE=infinity to enable coredump.</description>
    </item>
    
    <item>
      <title>Python Web 应用性能调优</title>
      <link>https://blog.monsterxx03.com/2017/07/01/python-web-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</link>
      <pubDate>Sat, 01 Jul 2017 23:38:24 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/07/01/python-web-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</guid>
      <description>Python web 应用性能调优 为了快速上线，早期很多代码基本是怎么方便怎么来，这样就留下了很多隐患，性能也不是很理想，python 因为 GIL 的原因，在性能上有天然劣势，即使用了 gevent/eventlet 这种协程方案，也很容易因为耗时的 CPU 操作阻塞住整个进程。前阵子对基础代码做了些重构，效果显著，记录一些。
设定目标:
 性能提高了，最直接的效果当然是能用更少的机器处理相同流量，目标是关闭 20% 的 stateless webserver. 尽量在框架代码上做改动，不动业务逻辑代码。 低风险 (历史经验告诉我们，动态一时爽，重构火葬场&amp;hellip;.)  治标 常见场景是大家开开心心做完一个 feature， sandbox 测试也没啥问题，上线了，结果 server load 飙升，各种 timeout 都来了，要么 rollback 代码，要么加机器。问题代码在哪?
我们监控用的是 datadog (statsd协议)，对这种问题最有效的指标是看每个接口的 avg_latency * req_count 得到每个接口在一段时间内的总耗时，在柱状图上最长的那块就是对性能影响最大的接口。进一步的调试就靠 cProfile 和读代码了。
但很多时候出问题的代码逻辑巨复杂，还很多人改动过，开发和 sandbox 环境数据的量和线上差距太大，无法复现问题，在线上用 cProfile 只能测只读接口(为了不写坏用户数据)。
而且这种方式只能治标，调试个别慢的业务接口，目标里说了只想改框架，提高整体性能，怎么整?
治本 我希望能对运行时进程状态打 snapshot，每次快照记录下当前的函数调用栈，叠合多次采样，出现次数多的函数必然就是瓶颈所在. 这思想在其他语言里用的也很多，其实就是 Brendan Gregg 的 flamegraph.
以前内部做过类似的事情，不过代码是侵入式的，在运行时通过 signal, inspect, traceback 等模块，定期打调用栈的 snapshot, 输出到文件，转成 svg 的 flamegraph 来看，但是 overhead 太高，后来弃用了。</description>
    </item>
    
    <item>
      <title>Build deb repository with fpm , aptly and s3</title>
      <link>https://blog.monsterxx03.com/2017/06/23/build-deb-repository-with-fpm-aptly-and-s3/</link>
      <pubDate>Fri, 23 Jun 2017 09:40:58 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/06/23/build-deb-repository-with-fpm-aptly-and-s3/</guid>
      <description>I&amp;#8217;m lazy, I don&amp;#8217;t want to be deb/rpm expert, I don&amp;#8217;t want to maintain repo server. I want as less maintenance effort as possible. 🙂
Combine tools fpm, aptly with aws s3, we can do it.
Use fpm to convert python package to deb fpm can transform python/gem/npm/dir/&amp;#8230; to deb/rpm/solaris/&amp;#8230; packages
Example:
fpm -s python -t deb -m xyj.asmy@gmail.com --verbose -v 0.10.1 --python-pip /usr/local/pip Flask  It will transform Flask 0.</description>
    </item>
    
    <item>
      <title>Debug python performance issue with pyflame</title>
      <link>https://blog.monsterxx03.com/2017/06/05/debug-python-performance-issue-with-pyflame/</link>
      <pubDate>Mon, 05 Jun 2017 09:50:44 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/06/05/debug-python-performance-issue-with-pyflame/</guid>
      <description>pyflame is an opensource tool developed by uber: https://github.com/uber/pyflame
It can take snapshots of running python process, combined with flamegraph.pl, can output flamegraph picture of python call stacks. Help analyze bottleneck of python program, needn&amp;#8217;t inject any perf code into your application, and overhead is very low.
Basic Usage sudo pyflame -s 10 -x -r 0.001 $pid | ./flamegraph.pl &amp;gt; perf.svg
 -s, how many seconds to run -r, sample rate (seconds)  Your output will be something like following:</description>
    </item>
    
    <item>
      <title>Designing data intensive application, reading notes, Part 2</title>
      <link>https://blog.monsterxx03.com/2017/05/17/designing-data-intensive-application-reading-notes-part-2/</link>
      <pubDate>Wed, 17 May 2017 09:12:44 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/05/17/designing-data-intensive-application-reading-notes-part-2/</guid>
      <description>Chapter 4, 5, 6
Encoding formats xml, json, msgpack are text based encoding format, they can&amp;#8217;t carry binary bytes (useless you encode them in base64, size grows 33%). And they cary schema definition with data, wast a lot of space.
thrift, protobuf are binary format, can take binary bytes, only carry data, the schema is defined with IDL(interface definition language). They have code generation tool to generate code to encode and decode data, along with check.</description>
    </item>
    
    <item>
      <title>Designing data intensive application, reading notes, Part 1</title>
      <link>https://blog.monsterxx03.com/2017/05/04/designing-data-intensive-application-reading-notes-part-1/</link>
      <pubDate>Thu, 04 May 2017 16:27:52 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/05/04/designing-data-intensive-application-reading-notes-part-1/</guid>
      <description>&lt;p&gt;Notes when reading chapter 2 &amp;#8220;Data models and query languages&amp;#8221;, chapter 3 &amp;#8220;Storage and retrieval&amp;#8221;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Infrastructure as Code</title>
      <link>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</link>
      <pubDate>Fri, 21 Apr 2017 16:25:07 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</guid>
      <description>&lt;p&gt;Create virtual resource on AWS is very convenient, but how to manage them will be a problem when your size grow.&lt;/p&gt;

&lt;p&gt;You will come to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How to explain the detail online settings for your colleagues (like: how our prod vpc is setup?what&amp;#8217;s the DHCP option set?), navigate around AWS console is okay, but not convenient.&lt;/li&gt;
&lt;li&gt;Who did what to which resource at when? AWS have a service called &lt;code&gt;Config&lt;/code&gt;, can be used to track this change, but if you want to make things as clear as viewing git log, still a lot of works to do.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ideally, we should manage AWS resources like code, all changes kept in VCS, so called &lt;code&gt;Infrastructure as Code&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;ve tried three ways to do it:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ansible&lt;/li&gt;
&lt;li&gt;CloudFormation&lt;/li&gt;
&lt;li&gt;terraform&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this article, I&amp;#8217;ll compare them, however, the conclusion is to use terraform 🙂&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Concurrency in Go, Reading Notes</title>
      <link>https://blog.monsterxx03.com/2017/04/19/concurrency-in-go-reading-notes/</link>
      <pubDate>Wed, 19 Apr 2017 16:26:58 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/19/concurrency-in-go-reading-notes/</guid>
      <description>&lt;p&gt;A few notes taken when reading &lt;Concurrency in Go&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MySQL partition table</title>
      <link>https://blog.monsterxx03.com/2017/04/05/mysql-partition-table/</link>
      <pubDate>Wed, 05 Apr 2017 16:23:32 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/05/mysql-partition-table/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;

&lt;p&gt;MySQL has buildin partition table support, which can help split data accross multi tables,&lt;/p&gt;

&lt;p&gt;and provide a unified query interface as normal tables.&lt;/p&gt;

&lt;p&gt;Benefit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Easy data management: If we need to archive old data, and our table is partitioned by datetime, we can drop old partition directly.&lt;/li&gt;
&lt;li&gt;Speed up query based on partition key(partitoin pruning)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Limit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For partition table, every unique key must use every column in table&amp;#8217;s partition expression(include primary key)&lt;/li&gt;
&lt;li&gt;For innodb engine, paritioned table can&amp;#8217;t have foreign key,and can&amp;#8217;t have columns referenced by foreign keys.&lt;/li&gt;
&lt;li&gt;For MyISAM engine, mysql version &amp;lt;= 5.6.5, DML operation will lock all partition as a whole.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ElasticSearch cluster</title>
      <link>https://blog.monsterxx03.com/2017/03/22/elasticsearch-cluster/</link>
      <pubDate>Wed, 22 Mar 2017 16:22:32 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/03/22/elasticsearch-cluster/</guid>
      <description>&lt;p&gt;In this article, let&amp;#8217;s talk about ElasticSearch&amp;#8217;s cluster mode, which means multi nodes ElasticSearch.&lt;/p&gt;

&lt;h2 id=&#34;basic-concepts&#34;&gt;Basic concepts&lt;/h2&gt;

&lt;p&gt;cluster: A collection of server nodes with same &lt;code&gt;cluster.name&lt;/code&gt; settings in elasticsearch.yaml&lt;/p&gt;

&lt;p&gt;primary shards: Divide a index into multi parts(by default 5), shards of an index can be distributed over multi nodes. It enables scale index horizontally and make access to index parallelly(accross multi nodes).&lt;/p&gt;

&lt;p&gt;replicas: backup for shards, also replicas can handle search requests, which means you can scale your search capacity horizontally via replicas.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bigtable notes</title>
      <link>https://blog.monsterxx03.com/2016/12/11/bigtable-notes/</link>
      <pubDate>Sun, 11 Dec 2016 16:20:24 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/12/11/bigtable-notes/</guid>
      <description>&lt;p&gt;杂乱笔记，辅助读paper.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GFS notes</title>
      <link>https://blog.monsterxx03.com/2016/11/19/gfs-notes/</link>
      <pubDate>Sat, 19 Nov 2016 16:18:41 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/11/19/gfs-notes/</guid>
      <description>&lt;p&gt;看了下很久前 google 的 GFS 论文， 做点笔记。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migrate to encrypted RDS</title>
      <link>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</link>
      <pubDate>Fri, 28 Oct 2016 16:17:30 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</guid>
      <description>&lt;p&gt;最近公司在做 HIPAA Compliance 相关的事情，其中要求之一是所有db需要开启encryption.&lt;/p&gt;

&lt;p&gt;比较麻烦的是rds 的encryption 只能在创建的时候设定，无法之后修改, 所以必须对线上的db 做一次 migration.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MySQL 索引优化</title>
      <link>https://blog.monsterxx03.com/2016/07/26/mysql-index-optimization/</link>
      <pubDate>Tue, 26 Jul 2016 16:13:54 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/07/26/mysql-index-optimization/</guid>
      <description>&lt;p&gt;什么是索引,索引怎么建这些基本的就跳过不谈了,整理一些前段时间优化线上 SQL 查询时碰到的一些问题. 主要解决下面几个问题:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;建立索引怎样选择合适的列.&lt;/li&gt;
&lt;li&gt;怎样让 SQL 能有效利用索引.&lt;/li&gt;
&lt;li&gt;如果对 SQL 效率进行评估(即设置索引前后是否真的有性能提升).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redshift as data warehouse</title>
      <link>https://blog.monsterxx03.com/2016/07/16/redshift-as-data-warehouse/</link>
      <pubDate>Sat, 16 Jul 2016 16:11:39 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/07/16/redshift-as-data-warehouse/</guid>
      <description>&lt;p&gt;Glow 的 server infrastructure 全部搭建在 AWS 上，一般要选择一些基础服务的时候，总是先看 AWS, 只要功能和成本符合要求，不会特意选择开源方案。&lt;/p&gt;

&lt;p&gt;数据仓库我们选择了 AWS 的 Redshift.&lt;/p&gt;

&lt;p&gt;在一年多的使用过程中 Redshift 的性能和稳定性都不错, 当然也有一些坑, 这里整理下在使用 redshift 的过程中的一些经验和遇到的坑.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MySQL innodb buffer pool</title>
      <link>https://blog.monsterxx03.com/2016/07/16/mysql-innodb-buffer-pool/</link>
      <pubDate>Sat, 16 Jul 2016 16:07:14 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/07/16/mysql-innodb-buffer-pool/</guid>
      <description>&lt;p&gt;最近在对公司的 MySQL 服务器做性能优化, 一直对 innodb 的内存使用方式不是很清楚, 乘这机会做点总结.&lt;/p&gt;

&lt;p&gt;在配置 MySQL 的时候, 一般都会需要设置 _innodb_buffer_pool&lt;em&gt;size&lt;/em&gt;, 在将 MySQL 设置在单独的服务器上时, 一般会设置为物理内存的80%.&lt;/p&gt;

&lt;p&gt;之前一直疑惑 MySQL 是怎么缓存数据的(不是指query cache), 直觉应该是LRU, 但如果 query 一下从磁盘上读取大量的数据的话(全表扫描或是 mysqldump), 是不是很容易就会把热数据给踢出去?&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>